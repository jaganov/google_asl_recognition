#!/usr/bin/env python3
"""
–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ CUDA - –î–û –∏ –ü–û–°–õ–ï –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch
"""

import torch
import time
import subprocess

def test_cuda_compatibility():
    print("üîç –¢–ï–°–¢ –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò CUDA")
    print("="*50)
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–∏—Å—Ç–µ–º–µ
    print(f"üîó PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
    print(f"üî• PyTorch CUDA –≤–µ—Ä—Å–∏—è: {torch.version.cuda}")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ CUDA
    cuda_available = torch.cuda.is_available()
    print(f"‚ö° CUDA –¥–æ—Å—Ç—É–ø–Ω–∞: {'‚úÖ –î–ê' if cuda_available else '‚ùå –ù–ï–¢'}")
    
    if not cuda_available:
        print("\nüö® –ü–†–û–ë–õ–ï–ú–ê: PyTorch –Ω–µ –≤–∏–¥–∏—Ç CUDA!")
        print("–í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        print("   ‚Ä¢ –ù–µ—Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –≤–µ—Ä—Å–∏–π CUDA")
        print("   ‚Ä¢ –î—Ä–∞–π–≤–µ—Ä NVIDIA —É—Å—Ç–∞—Ä–µ–ª")
        print("   ‚Ä¢ PyTorch —Å–æ–±—Ä–∞–Ω –±–µ–∑ CUDA –ø–æ–¥–¥–µ—Ä–∂–∫–∏")
        return False
    
    # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU
    print(f"üéÆ GPU: {torch.cuda.get_device_name(0)}")
    print(f"üíæ VRAM: {torch.cuda.get_device_properties(0).total_memory // 1024**3} GB")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –¥—Ä–∞–π–≤–µ—Ä–∞ —á–µ—Ä–µ–∑ nvidia-smi
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        for line in result.stdout.split('\n'):
            if 'CUDA Version' in line:
                driver_cuda = line.split('CUDA Version: ')[1].split()[0]
                print(f"üèóÔ∏è  –î—Ä–∞–π–≤–µ—Ä –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç CUDA: {driver_cuda}")
                break
    except:
        print("‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –≤–µ—Ä—Å–∏—é –¥—Ä–∞–π–≤–µ—Ä–∞")
    
    # –ö–†–ò–¢–ò–ß–ï–°–ö–ò–ô –¢–ï–°–¢: –°–∫–æ—Ä–æ—Å—Ç—å –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    print("\nüß™ –¢–ï–°–¢ –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò:")
    
    # CPU —Ç–µ—Å—Ç
    x_cpu = torch.randn(2000, 2000)
    y_cpu = torch.randn(2000, 2000)
    
    start_time = time.time()
    z_cpu = torch.mm(x_cpu, y_cpu)
    cpu_time = time.time() - start_time
    print(f"üñ•Ô∏è  CPU –≤—Ä–µ–º—è: {cpu_time:.3f}s")
    
    # GPU —Ç–µ—Å—Ç
    try:
        x_gpu = torch.randn(2000, 2000).cuda()
        y_gpu = torch.randn(2000, 2000).cuda()
        
        # –ü—Ä–æ–≥—Ä–µ–≤ GPU
        torch.mm(x_gpu, y_gpu)
        torch.cuda.synchronize()
        
        start_time = time.time()
        z_gpu = torch.mm(x_gpu, y_gpu)
        torch.cuda.synchronize()
        gpu_time = time.time() - start_time
        
        print(f"üéÆ GPU –≤—Ä–µ–º—è: {gpu_time:.3f}s")
        
        speedup = cpu_time / gpu_time
        print(f"üöÄ –£—Å–∫–æ—Ä–µ–Ω–∏–µ: {speedup:.1f}x")
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç–∏
        z_gpu_cpu = z_gpu.cpu()
        diff = torch.abs(z_cpu - z_gpu_cpu).max().item()
        print(f"üéØ –¢–æ—á–Ω–æ—Å—Ç—å: {diff:.2e} (–¥–æ–ª–∂–Ω–æ –±—ã—Ç—å < 1e-3)")
        
        # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        memory_used = torch.cuda.memory_allocated() // 1024**2
        print(f"üìä VRAM –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {memory_used} MB")
        
        # –û—Ü–µ–Ω–∫–∞ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        if speedup > 5 and diff < 1e-3:
            print("\nüéâ –û–¢–õ–ò–ß–ù–û! CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
            print(f"‚úÖ RTX 4070 –¥–∞–µ—Ç {speedup:.1f}x —É—Å–∫–æ—Ä–µ–Ω–∏–µ")
            return True
        elif speedup > 1:
            print(f"\n‚ö†Ô∏è  CUDA —Ä–∞–±–æ—Ç–∞–µ—Ç, –Ω–æ –º–µ–¥–ª–µ–Ω–Ω–æ ({speedup:.1f}x)")
            print("–í–æ–∑–º–æ–∂–Ω–æ –µ—Å—Ç—å –ø—Ä–æ–±–ª–µ–º—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏")
            return False
        else:
            print(f"\n‚ùå –ü–†–û–ë–õ–ï–ú–ê! GPU –º–µ–¥–ª–µ–Ω–Ω–µ–µ CPU!")
            print("–°–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –∏–¥—É—Ç –Ω–∞ CPU")
            return False
            
    except Exception as e:
        print(f"\n‚ùå –û–®–ò–ë–ö–ê GPU —Ç–µ—Å—Ç–∞: {e}")
        print("–í–µ—Ä–æ—è—Ç–Ω–æ –ø—Ä–æ–±–ª–µ–º—ã —Å CUDA —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å—é")
        return False

def check_google_asl_readiness():
    print("\nüéØ –ì–û–¢–û–í–ù–û–°–¢–¨ –ö GOOGLE ASL –ü–†–û–ï–ö–¢–£:")
    print("="*50)
    
    if not torch.cuda.is_available():
        print("‚ùå –ù–µ –≥–æ—Ç–æ–≤: CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
        return
    
    try:
        # –¢–µ—Å—Ç –±–∞—Ç—á–∞ –¥–ª—è Google ASL (–∫–∞–∫ –≤ —Ä–µ–∞–ª—å–Ω–æ–º –ø—Ä–æ–µ–∫—Ç–µ)
        batch_size = 8
        frames = 16
        channels = 3
        height = width = 224
        
        print(f"üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –±–∞—Ç—á: {batch_size}x{frames}x{channels}x{height}x{width}")
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π –±–∞—Ç—á –≤–∏–¥–µ–æ
        video_batch = torch.randn(batch_size, frames, channels, height, width).cuda()
        
        # –°–∏–º—É–ª–∏—Ä—É–µ–º forward pass CNN
        start_time = time.time()
        
        # Flatten frames –¥–ª—è CNN
        reshaped = video_batch.view(-1, channels, height, width)
        
        # –ü—Ä–æ—Å—Ç–∞—è —Å–∏–º—É–ª—è—Ü–∏—è CNN —Å–ª–æ–µ–≤
        conv1 = torch.nn.Conv2d(3, 64, 3, padding=1).cuda()
        conv2 = torch.nn.Conv2d(64, 128, 3, padding=1).cuda()
        pool = torch.nn.AdaptiveAvgPool2d(1).cuda()
        
        with torch.no_grad():
            x = torch.relu(conv1(reshaped))
            x = torch.relu(conv2(x))
            x = pool(x)
        
        forward_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–∞–º—è—Ç–∏
        memory_used = torch.cuda.memory_allocated() // 1024**2
        memory_total = torch.cuda.get_device_properties(0).total_memory // 1024**2
        memory_percent = memory_used / memory_total * 100
        
        print(f"‚è±Ô∏è  Forward pass: {forward_time:.3f}s")
        print(f"üìä –ü–∞–º—è—Ç—å: {memory_used}MB / {memory_total}MB ({memory_percent:.1f}%)")
        
        if forward_time < 0.1 and memory_percent < 50:
            print("üéâ –û–¢–õ–ò–ß–ù–û! –ì–æ—Ç–æ–≤ –∫ Google ASL –ø—Ä–æ–µ–∫—Ç—É!")
            print(f"‚úÖ –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞—Ç—á —Ä–∞–∑–º–µ—Ä {batch_size}")
        elif forward_time < 0.2:
            print("‚úÖ –•–æ—Ä–æ—à–æ! –ì–æ—Ç–æ–≤ –∫ –ø—Ä–æ–µ–∫—Ç—É")
            print("üí° –í–æ–∑–º–æ–∂–Ω–æ —Å—Ç–æ–∏—Ç —É–º–µ–Ω—å—à–∏—Ç—å –±–∞—Ç—á –¥–æ 4-6")
        else:
            print("‚ö†Ô∏è  –ú–µ–¥–ª–µ–Ω–Ω–æ –¥–ª—è –ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ–π —Ä–∞–±–æ—Ç—ã")
            print("üîß –ù—É–∂–Ω–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è –∏–ª–∏ –º–µ–Ω—å—à–∏–π –±–∞—Ç—á")
            
    except torch.cuda.OutOfMemoryError:
        print("‚ùå –ù–µ—Ö–≤–∞—Ç–∫–∞ VRAM –¥–ª—è –±–∞—Ç—á–∞ —Ä–∞–∑–º–µ—Ä 8")
        print("üí° –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –±–∞—Ç—á —Ä–∞–∑–º–µ—Ä 2-4")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∞: {e}")

if __name__ == "__main__":
    print("üöÄ –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò CUDA")
    print("–ó–∞–ø—É—Å—Ç–∏—Ç–µ —ç—Ç–æ—Ç —Ç–µ—Å—Ç –î–û –∏ –ü–û–°–õ–ï –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∏ PyTorch\n")
    
    success = test_cuda_compatibility()
    
    if success:
        check_google_asl_readiness()
    
    print(f"\n{'='*50}")
    if success:
        print("üéØ –†–ï–ó–£–õ–¨–¢–ê–¢: –°–∏—Å—Ç–µ–º–∞ —Ä–∞–±–æ—Ç–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω–æ!")
    else:
        print("üîß –†–ï–ó–£–õ–¨–¢–ê–¢: –ù—É–∂–Ω–∞ –ø–µ—Ä–µ—É—Å—Ç–∞–Ω–æ–≤–∫–∞ PyTorch!")
        print("üí° –ö–æ–º–∞–Ω–¥–∞: pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")