import pandas as pd
import json
import os
import shutil
from collections import Counter
from tqdm import tqdm
import numpy as np
import random

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã
INPUT_CSV = 'manual/dataset25/train.csv'
INPUT_MAP = 'manual/dataset25/sign_to_prediction_index_map.json'
INPUT_LANDMARKS = 'manual/dataset25/train_landmark_files'

# –í—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
OUTPUT_BASE = 'manual/dataset25_split'
TRAIN_DIR = os.path.join(OUTPUT_BASE, 'train')
TEST_DIR = os.path.join(OUTPUT_BASE, 'test')

# –ü–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
TEST_SIZE = 0.2  # 20% –¥–ª—è —Ç–µ—Å—Ç–∞
RANDOM_STATE = 42  # –î–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏

def analyze_dataset(df):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è"""
    print("=== –ê–ù–ê–õ–ò–ó –î–ê–¢–ê–°–ï–¢–ê ===")
    print(f"–í—Å–µ–≥–æ –∑–∞–ø–∏—Å–µ–π: {len(df)}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤: {df['participant_id'].nunique()}")
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Å–ª–æ–≤: {df['sign'].nunique()}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º
    participant_stats = df['participant_id'].value_counts()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º:")
    print(f"–ú–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –æ—Ç –æ–¥–Ω–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞: {participant_stats.max()}")
    print(f"–ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –æ—Ç –æ–¥–Ω–æ–≥–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞: {participant_stats.min()}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–∏—Å–µ–π –Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–∞: {participant_stats.mean():.1f}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ª–æ–≤–∞–º
    sign_stats = df['sign'].value_counts()
    print(f"\n–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Å–ª–æ–≤–∞–º:")
    print(f"–ú–∞–∫—Å–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞: {sign_stats.max()}")
    print(f"–ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –¥–ª—è –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞: {sign_stats.min()}")
    print(f"–°—Ä–µ–¥–Ω–µ–µ –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Å–ª–æ–≤–æ: {sign_stats.mean():.1f}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É—á–∞—Å—Ç–Ω–∏–∫–∏ —Å –∑–∞–ø–∏—Å—è–º–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞
    participant_word_counts = df.groupby('participant_id')['sign'].nunique()
    single_word_participants = participant_word_counts[participant_word_counts == 1]
    print(f"\n–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ —Å –æ–¥–Ω–∏–º —Å–ª–æ–≤–æ–º: {len(single_word_participants)}")
    
    return participant_stats, sign_stats, participant_word_counts

def create_stratified_split(df, test_size=0.2, random_state=42):
    """
    –°–æ–∑–¥–∞–µ—Ç —Å—Ç—Ä–∞—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —Å —É—á–µ—Ç–æ–º –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –∂–µ—Å—Ç–æ–≤:
    1. –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ —É—á–∞—Å—Ç–Ω–∏–∫–∞–º, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å —É—Ç–µ—á–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    2. –û–±–µ—Å–ø–µ—á–∏–≤–∞–µ–º –±–∞–ª–∞–Ω—Å –ø–æ —Å–ª–æ–≤–∞–º –≤ train –∏ test
    3. –£—á–∏—Ç—ã–≤–∞–µ–º, —á—Ç–æ —ç—Ç–æ –∞–Ω–∏–º–∞—Ü–∏–∏ –∂–µ—Å—Ç–æ–≤ –æ—Ç –æ–¥–Ω–∏—Ö –∏ —Ç–µ—Ö –∂–µ –ª—é–¥–µ–π
    """
    print("\n=== –°–û–ó–î–ê–ù–ò–ï –†–ê–ó–î–ï–õ–ï–ù–ò–Ø ===")
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤
    unique_participants = df['participant_id'].unique()
    print(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è: {len(unique_participants)}")
    
    # –°–æ–∑–¥–∞–µ–º —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏—é –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤ —É —É—á–∞—Å—Ç–Ω–∏–∫–∞
    participant_word_counts = df.groupby('participant_id')['sign'].nunique()
    
    # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –ø–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤—É —Å–ª–æ–≤ (–¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏)
    word_count_bins = pd.cut(participant_word_counts, bins=5, labels=['very_low', 'low', 'medium', 'high', 'very_high'])
    
    # –°–æ–∑–¥–∞–µ–º DataFrame –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è
    split_df = pd.DataFrame({
        'participant_id': unique_participants,
        'word_count': participant_word_counts.values,
        'word_count_bin': word_count_bins.values
    })
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º seed –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    random.seed(random_state)
    np.random.seed(random_state)
    
    # –ü—Ä–æ—Å—Ç–æ–µ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –Ω–∞ train –∏ test
    participants_list = unique_participants.tolist()
    random.shuffle(participants_list)
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –ø–æ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏
    split_idx = int(len(participants_list) * (1 - test_size))
    train_participants = participants_list[:split_idx]
    test_participants = participants_list[split_idx:]
    
    print(f"–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ train: {len(train_participants)}")
    print(f"–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ test: {len(test_participants)}")
    
    # –†–∞–∑–¥–µ–ª—è–µ–º –¥–∞–Ω–Ω—ã–µ
    train_df = df[df['participant_id'].isin(train_participants)].copy()
    test_df = df[df['participant_id'].isin(test_participants)].copy()
    
    print(f"–ó–∞–ø–∏—Å–µ–π –≤ train: {len(train_df)}")
    print(f"–ó–∞–ø–∏—Å–µ–π –≤ test: {len(test_df)}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–∞–ª–∞–Ω—Å –ø–æ —Å–ª–æ–≤–∞–º
    print("\n=== –ü–†–û–í–ï–†–ö–ê –ë–ê–õ–ê–ù–°–ê ===")
    train_signs = train_df['sign'].value_counts()
    test_signs = test_df['sign'].value_counts()
    
    print("–°–ª–æ–≤–∞ –≤ train:")
    for sign, count in train_signs.items():
        print(f"  {sign}: {count}")
    
    print("\n–°–ª–æ–≤–∞ –≤ test:")
    for sign, count in test_signs.items():
        print(f"  {sign}: {count}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –≤—Å–µ —Å–ª–æ–≤–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ –æ–±–æ–∏—Ö –Ω–∞–±–æ—Ä–∞—Ö
    train_sign_set = set(train_signs.index)
    test_sign_set = set(test_signs.index)
    all_signs = set(df['sign'].unique())
    
    missing_in_train = all_signs - train_sign_set
    missing_in_test = all_signs - test_sign_set
    
    if missing_in_train:
        print(f"\n‚ö†Ô∏è  –°–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ train: {missing_in_train}")
    if missing_in_test:
        print(f"‚ö†Ô∏è  –°–ª–æ–≤–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ test: {missing_in_test}")
    
    if not missing_in_train and not missing_in_test:
        print("\n‚úÖ –í—Å–µ —Å–ª–æ–≤–∞ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ train –∏ test")
    
    return train_df, test_df

def copy_files_for_split(df, output_dir, split_name):
    """–ö–æ–ø–∏—Ä—É–µ—Ç —Ñ–∞–π–ª—ã –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö"""
    print(f"\n=== –ö–û–ü–ò–†–û–í–ê–ù–ò–ï –§–ê–ô–õ–û–í –î–õ–Ø {split_name.upper()} ===")
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
    os.makedirs(output_dir, exist_ok=True)
    
    # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –ø—É—Ç–∏
    unique_paths = df['path'].unique()
    copied_count = 0
    skipped_count = 0
    
    with tqdm(total=len(unique_paths), desc=f"–ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ {split_name}") as pbar:
        for rel_path in unique_paths:
            src = os.path.join('manual/dataset25', rel_path)
            dst = os.path.join(output_dir, rel_path)
            dst_dir = os.path.dirname(dst)
            
            try:
                os.makedirs(dst_dir, exist_ok=True)
                if not os.path.exists(dst):
                    shutil.copy2(src, dst)
                    copied_count += 1
                else:
                    skipped_count += 1
            except Exception as e:
                print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ –∫–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–∏ {rel_path}: {e}')
                skipped_count += 1
            pbar.update(1)
    
    print(f'–°–∫–æ–ø–∏—Ä–æ–≤–∞–Ω–æ —Ñ–∞–π–ª–æ–≤ –¥–ª—è {split_name}: {copied_count}')
    print(f'–ü—Ä–æ–ø—É—â–µ–Ω–æ (—É–∂–µ —Å—É—â–µ—Å—Ç–≤—É—é—Ç): {skipped_count}')
    return copied_count, skipped_count

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–∞"""
    print("üöÄ –ù–ê–ß–ê–õ–û –†–ê–ó–î–ï–õ–ï–ù–ò–Ø –î–ê–¢–ê–°–ï–¢–ê –ù–ê TRAIN –ò TEST")
    print("=" * 60)
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
    print('–ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...')
    df = pd.read_csv(INPUT_CSV)
    
    # 2. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É
    participant_stats, sign_stats, participant_word_counts = analyze_dataset(df)
    
    # 3. –°–æ–∑–¥–∞–µ–º —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–µ
    train_df, test_df = create_stratified_split(df, TEST_SIZE, RANDOM_STATE)
    
    # 4. –°–æ–∑–¥–∞–µ–º –≤—ã—Ö–æ–¥–Ω—ã–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    os.makedirs(OUTPUT_BASE, exist_ok=True)
    
    # 5. –°–æ—Ö—Ä–∞–Ω—è–µ–º CSV —Ñ–∞–π–ª—ã
    train_csv = os.path.join(TRAIN_DIR, 'train.csv')
    test_csv = os.path.join(TEST_DIR, 'train.csv')  # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ –∂–µ –∏–º—è –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
    
    train_df.to_csv(train_csv, index=False)
    test_df.to_csv(test_csv, index=False)
    
    print(f'\n–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ train.csv: {train_csv}')
    print(f'–°–æ—Ö—Ä–∞–Ω–µ–Ω–æ test.csv: {test_csv}')
    
    # 6. –ö–æ–ø–∏—Ä—É–µ–º sign_to_prediction_index_map.json –≤ –æ–±–µ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
    for output_dir in [TRAIN_DIR, TEST_DIR]:
        shutil.copy2(INPUT_MAP, os.path.join(output_dir, 'sign_to_prediction_index_map.json'))
    
    # 7. –ö–æ–ø–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –¥–∞–Ω–Ω—ã—Ö
    copy_files_for_split(train_df, TRAIN_DIR, 'train')
    copy_files_for_split(test_df, TEST_DIR, 'test')
    
    # 8. –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print("\n" + "=" * 60)
    print("üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    print("=" * 60)
    
    print(f"–ò—Å—Ö–æ–¥–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç: {len(df)} –∑–∞–ø–∏—Å–µ–π")
    print(f"Train –Ω–∞–±–æ—Ä: {len(train_df)} –∑–∞–ø–∏—Å–µ–π ({len(train_df)/len(df)*100:.1f}%)")
    print(f"Test –Ω–∞–±–æ—Ä: {len(test_df)} –∑–∞–ø–∏—Å–µ–π ({len(test_df)/len(df)*100:.1f}%)")
    
    print(f"\n–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ train: {train_df['participant_id'].nunique()}")
    print(f"–£—á–∞—Å—Ç–Ω–∏–∫–æ–≤ –≤ test: {test_df['participant_id'].nunique()}")
    
    print(f"\n–°–ª–æ–≤ –≤ train: {train_df['sign'].nunique()}")
    print(f"–°–ª–æ–≤ –≤ test: {test_df['sign'].nunique()}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Å–ª–æ–≤–æ
    train_min = train_df['sign'].value_counts().min()
    test_min = test_df['sign'].value_counts().min()
    
    print(f"\n–ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Å–ª–æ–≤–æ –≤ train: {train_min}")
    print(f"–ú–∏–Ω–∏–º—É–º –∑–∞–ø–∏—Å–µ–π –Ω–∞ —Å–ª–æ–≤–æ –≤ test: {test_min}")
    
    if train_min < 10 or test_min < 5:
        print("‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ù–µ–∫–æ—Ç–æ—Ä—ã–µ —Å–ª–æ–≤–∞ –∏–º–µ—é—Ç –º–∞–ª–æ –∑–∞–ø–∏—Å–µ–π!")
        print("   –†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏—è.")
    
    print("\n‚úÖ –†–ê–ó–î–ï–õ–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û!")
    print(f"üìÅ Train –¥–∞–Ω–Ω—ã–µ: {TRAIN_DIR}")
    print(f"üìÅ Test –¥–∞–Ω–Ω—ã–µ: {TEST_DIR}")

if __name__ == "__main__":
    main() 