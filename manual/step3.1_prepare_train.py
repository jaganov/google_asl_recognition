# ============================================================================
# –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø ASL –ú–û–î–ï–õ–¨ - –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ –° PYTORCH
# –ò—Å–ø—Ä–∞–≤–ª—è–µ—Ç –æ—à–∏–±–∫–∏ torch.interp –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–±–ª–µ–º—ã —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
# ============================================================================

import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset, DataLoader
from torch.optim import AdamW
from torch.optim.lr_scheduler import OneCycleLR, CosineAnnealingLR
import torch.nn.init as init
import numpy as np
import random
import math
from typing import List, Tuple, Optional
from tqdm import tqdm
import time
import matplotlib.pyplot as plt

# –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–µ–º–µ–Ω–∞ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
np.random.seed(42)
torch.manual_seed(42)
random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
    torch.cuda.manual_seed_all(42)

dtype = torch.float
dtype_long = torch.long
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

print(f"üöÄ –ò—Å–ø–æ–ª—å–∑—É–µ–º —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}")
if torch.cuda.is_available():
    print(f"   GPU: {torch.cuda.get_device_name(0)}")
    print(f"   –ü–∞–º—è—Ç—å GPU: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")

# ============================================================================
# –í–°–ü–û–ú–û–ì–ê–¢–ï–õ–¨–ù–´–ï –§–£–ù–ö–¶–ò–ò –î–õ–Ø –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–ò
# ============================================================================

def torch_interp(input, indices, values):
    """
    –°–æ–≤–º–µ—Å—Ç–∏–º–∞—è –≤–µ—Ä—Å–∏—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ –¥–ª—è —Å—Ç–∞—Ä—ã—Ö –≤–µ—Ä—Å–∏–π PyTorch
    """
    if hasattr(torch, 'interp'):
        return torch.interp(input, indices, values)
    else:
        # –†–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω—Ç–µ—Ä–ø–æ–ª—è—Ü–∏–∏ —á–µ—Ä–µ–∑ numpy
        input_np = input.detach().cpu().numpy()
        indices_np = indices.detach().cpu().numpy()
        values_np = values.detach().cpu().numpy()
        
        result = np.interp(input_np, indices_np, values_np)
        return torch.from_numpy(result).to(values.device).type(values.dtype)

def safe_atan2(y, x):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è atan2 —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∫—Ä–∞–µ–≤—ã—Ö —Å–ª—É—á–∞–µ–≤"""
    return torch.atan2(y + 1e-8, x + 1e-8)

def safe_norm(x, dim=-1, keepdim=False):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è norm —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –Ω—É–ª–µ–≤—ã—Ö –≤–µ–∫—Ç–æ—Ä–æ–≤"""
    return torch.norm(x + 1e-8, dim=dim, keepdim=keepdim)

# ============================================================================
# 1. –£–õ–£–ß–®–ï–ù–ù–´–ô PREPROCESSING –° –ë–û–ì–ê–¢–´–ú–ò –í–†–ï–ú–ï–ù–ù–´–ú–ò –ü–†–ò–ó–ù–ê–ö–ê–ú–ò
# ============================================================================

class FinalPreprocessingLayer(nn.Module):
    """
    –§–∏–Ω–∞–ª—å–Ω–∞—è –≤–µ—Ä—Å–∏—è preprocessing —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """
    def __init__(self, max_len=384):
        super().__init__()
        self.max_len = max_len
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω—ã–π –Ω–∞–±–æ—Ä landmarks –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        # –õ–∏—Ü–æ: –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏
        face_landmarks = [33, 133, 362, 263, 61, 291, 199, 419, 17, 84, 314, 405, 320, 307, 375, 321, 308, 324, 318]
        
        # –†—É–∫–∏ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã)
        left_hand = list(range(468, 489)) if 489 <= 543 else []
        right_hand = list(range(522, 543)) if 543 <= 600 else []
        
        # –ü–æ–∑–∞ (–∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Ç–µ–ª–∞)
        pose_landmarks = [11, 12, 13, 14, 15, 16]
        
        self.selected_landmarks = face_landmarks + left_hand + right_hand + pose_landmarks
        print(f"üìä –í—ã–±—Ä–∞–Ω–æ {len(self.selected_landmarks)} –∫–ª—é—á–µ–≤—ã—Ö landmarks")
    
    def forward(self, x):
        """
        x: (batch_size, seq_len, num_landmarks, 3) –∏–ª–∏ (seq_len, num_landmarks, 3)
        """
        if x.dim() == 3:
            x = x.unsqueeze(0)
        
        batch_size, seq_len, num_landmarks, coords = x.shape
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –≤—ã–±–æ—Ä landmarks
        max_landmark = max(self.selected_landmarks) if self.selected_landmarks else 0
        if num_landmarks > max_landmark:
            try:
                x = x[:, :, self.selected_landmarks, :]
            except IndexError:
                # Fallback: –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ landmarks
                available_landmarks = [i for i in self.selected_landmarks if i < num_landmarks]
                if available_landmarks:
                    x = x[:, :, available_landmarks, :]
                else:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–≤—ã–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ landmarks
                    x = x[:, :, :min(50, num_landmarks), :]
        
        # –£–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        x = self._improved_normalization(x)
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –±–æ–≥–∞—Ç—ã–µ –≤—Ä–µ–º–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = self._extract_rich_temporal_features(x)
        
        # –û–±—Ä–µ–∑–∞–µ–º –¥–æ max_len
        if self.max_len and features.shape[1] > self.max_len:
            features = features[:, :self.max_len]
        
        return features
    
    def _improved_normalization(self, x):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —É–ª—É—á—à–µ–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è"""
        batch_size, seq_len = x.shape[:2]
        
        # –ü—Ä–æ—Å—Ç–∞—è –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        x_norm = x.clone()
        
        # –¶–µ–Ω—Ç—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Å—Ä–µ–¥–Ω–µ–≥–æ
        coords = x[..., :2]  # –¢–æ–ª—å–∫–æ x, y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ä–µ–¥–Ω–µ–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –∫–∞–¥—Ä–∞
        valid_mask = ~(torch.isnan(coords) | torch.isinf(coords))
        
        for b in range(batch_size):
            for t in range(seq_len):
                frame_coords = coords[b, t]
                frame_mask = valid_mask[b, t]
                
                if frame_mask.any():
                    valid_coords = frame_coords[frame_mask]
                    if len(valid_coords) > 0:
                        mean_coord = valid_coords.mean(dim=0)
                        x_norm[b, t, :, :2] = coords[b, t] - mean_coord
        
        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –º–∞—Å—à—Ç–∞–±–∞
        coords_flat = x_norm[..., :2].reshape(batch_size, seq_len, -1)
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ std
        for b in range(batch_size):
            for t in range(seq_len):
                frame_flat = coords_flat[b, t]
                valid_flat = frame_flat[~(torch.isnan(frame_flat) | torch.isinf(frame_flat))]
                
                if len(valid_flat) > 1:
                    std = torch.std(valid_flat)
                    if std > 1e-6:
                        coords_flat[b, t] = coords_flat[b, t] / std
        
        x_norm[..., :2] = coords_flat.reshape(x_norm[..., :2].shape)
        
        # –ó–∞–º–µ–Ω—è–µ–º NaN –∏ inf –Ω–∞ 0
        x_norm = torch.where(torch.isnan(x_norm) | torch.isinf(x_norm), 
                            torch.zeros_like(x_norm), x_norm)
        
        return x_norm
    
    def _extract_rich_temporal_features(self, x):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –±–æ–≥–∞—Ç—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å –±–µ–∑–æ–ø–∞—Å–Ω—ã–º–∏ –æ–ø–µ—Ä–∞—Ü–∏—è–º–∏"""
        batch_size, seq_len, num_landmarks, _ = x.shape
        coords = x[..., :2]  # –¢–æ–ª—å–∫–æ x, y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        
        # 1. –ü–æ–∑–∏—Ü–∏–∏ (–±–∞–∑–æ–≤—ã–µ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã)
        positions = coords
        
        # 2. –°–∫–æ—Ä–æ—Å—Ç–∏ (–ø–µ—Ä–≤–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è) - –±–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤–µ—Ä—Å–∏—è
        velocities = torch.zeros_like(coords)
        if seq_len > 1:
            velocities[:, 1:] = coords[:, 1:] - coords[:, :-1]
        
        # 3. –£—Å–∫–æ—Ä–µ–Ω–∏—è (–≤—Ç–æ—Ä–∞—è –ø—Ä–æ–∏–∑–≤–æ–¥–Ω–∞—è)
        accelerations = torch.zeros_like(coords)
        if seq_len > 2:
            accelerations[:, 2:] = velocities[:, 2:] - velocities[:, 1:-1]
        
        # 4. –ú–∞–≥–Ω–∏—Ç—É–¥–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏ (–±–µ–∑–æ–ø–∞—Å–Ω–∞—è)
        velocity_magnitude = safe_norm(velocities, dim=-1, keepdim=True)
        
        # 5. –ú–∞–≥–Ω–∏—Ç—É–¥–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
        acceleration_magnitude = safe_norm(accelerations, dim=-1, keepdim=True)
        
        # 6. –ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ (—Ç—Ä–∞–µ–∫—Ç–æ—Ä–∏—è)
        cumulative_distance = torch.zeros_like(velocity_magnitude)
        for t in range(1, seq_len):
            cumulative_distance[:, t] = cumulative_distance[:, t-1] + velocity_magnitude[:, t-1]
        
        # 7. –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –¥–≤–∏–∂–µ–Ω–∏—è (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π —É–≥–æ–ª —Å–∫–æ—Ä–æ—Å—Ç–∏)
        velocity_angle = safe_atan2(velocities[..., 1:2], velocities[..., 0:1])
        
        # 8. –ò–∑–º–µ–Ω–µ–Ω–∏–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏—è (–∫—Ä–∏–≤–∏–∑–Ω–∞)
        direction_change = torch.zeros_like(velocity_angle)
        if seq_len > 2:
            direction_change[:, 2:] = velocity_angle[:, 2:] - velocity_angle[:, 1:-1]
        
        # 9. –£–ø—Ä–æ—â–µ–Ω–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏
        hand_distances = self._compute_simple_distances(coords)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
        all_features = [
            positions.reshape(batch_size, seq_len, -1),                    # –ü–æ–∑–∏—Ü–∏–∏
            velocities.reshape(batch_size, seq_len, -1),                   # –°–∫–æ—Ä–æ—Å—Ç–∏
            accelerations.reshape(batch_size, seq_len, -1),                # –£—Å–∫–æ—Ä–µ–Ω–∏—è
            velocity_magnitude.reshape(batch_size, seq_len, -1),           # –ú–∞–≥–Ω–∏—Ç—É–¥–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏
            acceleration_magnitude.reshape(batch_size, seq_len, -1),       # –ú–∞–≥–Ω–∏—Ç—É–¥–∞ —É—Å–∫–æ—Ä–µ–Ω–∏—è
            cumulative_distance.reshape(batch_size, seq_len, -1),          # –ö—É–º—É–ª—è—Ç–∏–≤–Ω–æ–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
            velocity_angle.reshape(batch_size, seq_len, -1),               # –ù–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ
            direction_change.reshape(batch_size, seq_len, -1),             # –ö—Ä–∏–≤–∏–∑–Ω–∞
            hand_distances,                                                # –†–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É —Ç–æ—á–∫–∞–º–∏
        ]
        
        features = torch.cat(all_features, dim=-1)
        
        # –ó–∞–º–µ–Ω—è–µ–º NaN –∏ inf –Ω–∞ 0
        features = torch.where(torch.isnan(features) | torch.isinf(features), 
                              torch.zeros_like(features), features)
        
        return features
    
    def _compute_simple_distances(self, coords):
        """–£–ø—Ä–æ—â–µ–Ω–Ω–æ–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏"""
        batch_size, seq_len, num_landmarks, _ = coords.shape
        
        if num_landmarks < 3:
            return torch.zeros(batch_size, seq_len, 1, device=coords.device)
        
        # –ü—Ä–æ—Å—Ç—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –º–µ–∂–¥—É –ø–µ—Ä–≤—ã–º–∏ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ —Ç–æ—á–∫–∞–º–∏
        distances = []
        
        for i in range(min(3, num_landmarks - 1)):
            for j in range(i + 1, min(i + 3, num_landmarks)):
                if j < num_landmarks:
                    dist = safe_norm(coords[:, :, i] - coords[:, :, j], dim=-1, keepdim=True)
                    distances.append(dist)
        
        if distances:
            return torch.cat(distances, dim=-1)
        else:
            return torch.zeros(batch_size, seq_len, 1, device=coords.device)

# ============================================================================
# 2. ENHANCED TRANSFORMER BLOCK –° TEMPORAL ATTENTION
# ============================================================================

class EnhancedTransformerBlock(nn.Module):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π Transformer –±–ª–æ–∫ —Å dual attention (global + local temporal)
    """
    def __init__(self, dim, num_heads=8, expand=2, drop_rate=0.2, window_size=5):
        super().__init__()
        self.dim = dim
        self.num_heads = num_heads
        self.window_size = window_size
        
        # Global attention (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–º Transformer)
        self.global_attention = nn.MultiheadAttention(dim, num_heads, batch_first=True, dropout=drop_rate)
        self.global_norm = nn.LayerNorm(dim)
        
        # Local temporal attention (–∫–ª—é—á–µ–≤–æ–µ –Ω–æ–≤–æ–≤–≤–µ–¥–µ–Ω–∏–µ)
        self.temporal_attention = nn.MultiheadAttention(
            dim, max(1, num_heads//2), batch_first=True, dropout=drop_rate
        )
        self.temporal_norm = nn.LayerNorm(dim)
        
        # Fusion layer –¥–ª—è –æ–±—ä–µ–¥–∏–Ω–µ–Ω–∏—è global –∏ local
        self.attention_fusion = nn.Sequential(
            nn.Linear(dim * 2, dim * 2),
            nn.SiLU(),
            nn.Dropout(drop_rate),
            nn.Linear(dim * 2, dim)
        )
        
        # Feed-forward network
        self.ffn = nn.Sequential(
            nn.Linear(dim, dim * expand),
            nn.SiLU(),
            nn.Dropout(drop_rate),
            nn.Linear(dim * expand, dim),
            nn.Dropout(drop_rate)
        )
        self.ffn_norm = nn.LayerNorm(dim)
        
        # Stochastic depth –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏
        self.drop_path = StochasticDepth(drop_rate)
    
    def forward(self, x):
        batch_size, seq_len, dim = x.shape
        
        # 1. Global attention
        x_global, _ = self.global_attention(x, x, x)
        
        # 2. Local temporal attention
        x_local = self._apply_local_temporal_attention(x)
        
        # 3. Fusion
        x_combined = torch.cat([x_global, x_local], dim=-1)
        x_fused = self.attention_fusion(x_combined)
        
        # 4. Residual connection + normalization
        x = x + self.drop_path(x_fused)
        x = self.global_norm(x)
        
        # 5. Feed-forward
        x_ffn = self.ffn(x)
        x = x + self.drop_path(x_ffn)
        x = self.ffn_norm(x)
        
        return x
    
    def _apply_local_temporal_attention(self, x):
        """–ü—Ä–∏–º–µ–Ω—è–µ—Ç attention —Ç–æ–ª—å–∫–æ –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–Ω–æ–º –æ–∫–Ω–µ"""
        batch_size, seq_len, dim = x.shape
        output = torch.zeros_like(x)
        
        for i in range(seq_len):
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
            start_idx = max(0, i - self.window_size // 2)
            end_idx = min(seq_len, i + self.window_size // 2 + 1)
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º –ª–æ–∫–∞–ª—å–Ω–æ–µ –æ–∫–Ω–æ
            local_window = x[:, start_idx:end_idx, :]
            query = x[:, i:i+1, :]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º attention –≤ –ª–æ–∫–∞–ª—å–Ω–æ–º –æ–∫–Ω–µ
            attended, _ = self.temporal_attention(query, local_window, local_window)
            output[:, i:i+1, :] = attended
        
        return output

# ============================================================================
# 3. MULTI-SCALE TEMPORAL CNN
# ============================================================================

class MultiScaleTemporalConv(nn.Module):
    """
    –ú—É–ª—å—Ç–∏–º–∞—Å—à—Ç–∞–±–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∫–æ–Ω–≤–æ–ª—é—Ü–∏—è —Å —Ä–∞–∑–Ω—ã–º–∏ –¥–∏–ª–∞—Ç–∞—Ü–∏—è–º–∏
    """
    def __init__(self, dim, kernel_sizes=[3, 5, 7], dilations=[1, 2, 4], drop_rate=0.1):
        super().__init__()
        
        self.branches = nn.ModuleList()
        branch_dim = max(1, dim // len(kernel_sizes))
        
        for kernel_size, dilation in zip(kernel_sizes, dilations):
            padding = ((kernel_size - 1) * dilation) // 2  # –°–∏–º–º–µ—Ç—Ä–∏—á–Ω—ã–π padding
            branch = nn.Sequential(
                nn.Conv1d(dim, branch_dim, kernel_size, 
                         padding=padding, dilation=dilation),
                nn.BatchNorm1d(branch_dim),
                nn.SiLU(),
                nn.Dropout(drop_rate)
            )
            self.branches.append(branch)
        
        # Fusion layer
        total_branch_dim = branch_dim * len(kernel_sizes)
        self.fusion = nn.Sequential(
            nn.Conv1d(total_branch_dim, dim, 1),
            nn.BatchNorm1d(dim),
            nn.SiLU()
        )
        
        # Residual connection
        self.residual = nn.Conv1d(dim, dim, 1)
    
    def forward(self, x):
        # x: (batch, seq, dim) -> (batch, dim, seq)
        x = x.transpose(1, 2)
        residual = self.residual(x)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∫–∞–∂–¥—É—é –≤–µ—Ç–≤—å
        branch_outputs = []
        for branch in self.branches:
            branch_out = branch(x)
            branch_outputs.append(branch_out)
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏ fusion
        concat_output = torch.cat(branch_outputs, dim=1)
        fused = self.fusion(concat_output)
        
        # Residual connection
        output = fused + residual
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∫ (batch, seq, dim)
        return output.transpose(1, 2)

# ============================================================================
# 4. STOCHASTIC DEPTH –î–õ–Ø –†–ï–ì–£–õ–Ø–†–ò–ó–ê–¶–ò–ò
# ============================================================================

class StochasticDepth(nn.Module):
    """Stochastic Depth –¥–ª—è —Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏–∏ –≥–ª—É–±–æ–∫–∏—Ö –º–æ–¥–µ–ª–µ–π"""
    def __init__(self, drop_rate=0.1):
        super().__init__()
        self.drop_rate = drop_rate
    
    def forward(self, x):
        if not self.training or self.drop_rate == 0:
            return x
        
        keep_prob = 1 - self.drop_rate
        shape = (x.shape[0],) + (1,) * (x.ndim - 1)
        random_tensor = keep_prob + torch.rand(shape, dtype=x.dtype, device=x.device)
        random_tensor.floor_()
        
        return x.div(keep_prob) * random_tensor

# ============================================================================
# 5. –ì–õ–ê–í–ù–ê–Ø –£–õ–£–ß–®–ï–ù–ù–ê–Ø –ú–û–î–ï–õ–¨
# ============================================================================

class FinalASLModel(nn.Module):
    """
    –§–∏–Ω–∞–ª—å–Ω–∞—è ASL –º–æ–¥–µ–ª—å —Å –≤—Å–µ–º–∏ —É–ª—É—á—à–µ–Ω–∏—è–º–∏
    """
    def __init__(self, input_dim, num_classes, max_len=384, dim=256, num_layers=8):
        super().__init__()
        self.max_len = max_len
        self.dim = dim
        
        # Preprocessing
        self.preprocessing = FinalPreprocessingLayer(max_len)
        
        # –í—Ö–æ–¥–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        self.input_projection = nn.Sequential(
            nn.Linear(input_dim, dim // 2),
            nn.LayerNorm(dim // 2),
            nn.SiLU(),
            nn.Dropout(0.1),
            nn.Linear(dim // 2, dim),
            nn.LayerNorm(dim)
        )
        
        # –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        self.pos_encoding = PositionalEncoding(dim, max_len)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ –±–ª–æ–∫–∏ - —á–µ—Ä–µ–¥–æ–≤–∞–Ω–∏–µ CNN –∏ Transformer
        self.layers = nn.ModuleList()
        for i in range(num_layers):
            if i % 2 == 0:
                # Multi-scale CNN –¥–ª—è –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤
                self.layers.append(MultiScaleTemporalConv(dim))
            else:
                # Enhanced Transformer –¥–ª—è –≥–ª–æ–±–∞–ª—å–Ω—ã—Ö –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
                self.layers.append(EnhancedTransformerBlock(
                    dim, num_heads=8, window_size=5, drop_rate=0.1
                ))
        
        # Temporal attention pooling
        self.attention_pool = nn.Sequential(
            nn.Linear(dim, dim // 4),
            nn.Tanh(),
            nn.Linear(dim // 4, 1)
        )
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä
        self.classifier = nn.Sequential(
            nn.LayerNorm(dim),
            nn.Linear(dim, dim * 2),
            nn.SiLU(),
            nn.Dropout(0.3),
            nn.Linear(dim * 2, dim),
            nn.SiLU(),
            nn.Dropout(0.2),
            nn.Linear(dim, num_classes)
        )
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
        self.apply(self._init_weights)
    
    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.trunc_normal_(module.weight, std=0.02)
            if module.bias is not None:
                torch.nn.init.zeros_(module.bias)
        elif isinstance(module, nn.LayerNorm):
            torch.nn.init.zeros_(module.bias)
            torch.nn.init.ones_(module.weight)
        elif isinstance(module, nn.Conv1d):
            torch.nn.init.kaiming_normal_(module.weight, mode='fan_out', nonlinearity='relu')
    
    def forward(self, x):
        # Preprocessing
        x = self.preprocessing(x)
        
        # –í—Ö–æ–¥–Ω–∞—è –ø—Ä–æ–µ–∫—Ü–∏—è
        x = self.input_projection(x)
        
        # –ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ
        x = self.pos_encoding(x)
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Å–ª–æ–∏
        for layer in self.layers:
            x = layer(x)
        
        # Temporal attention pooling
        attention_weights = self.attention_pool(x)
        attention_weights = F.softmax(attention_weights, dim=1)
        pooled = torch.sum(x * attention_weights, dim=1)
        
        # –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è
        output = self.classifier(pooled)
        
        return output

# ============================================================================
# 6. –ü–û–ó–ò–¶–ò–û–ù–ù–û–ï –ö–û–î–ò–†–û–í–ê–ù–ò–ï
# ============================================================================

class PositionalEncoding(nn.Module):
    """–ü–æ–∑–∏—Ü–∏–æ–Ω–Ω–æ–µ –∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã"""
    def __init__(self, dim, max_len=5000):
        super().__init__()
        
        pe = torch.zeros(max_len, dim)
        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)
        div_term = torch.exp(torch.arange(0, dim, 2).float() * (-math.log(10000.0) / dim))
        
        pe[:, 0::2] = torch.sin(position * div_term)
        pe[:, 1::2] = torch.cos(position * div_term)
        pe = pe.unsqueeze(0)
        
        self.register_buffer('pe', pe)
    
    def forward(self, x):
        return x + self.pe[:, :x.size(1)]

# ============================================================================
# 7. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ê–£–ì–ú–ï–ù–¢–ê–¶–ò–Ø (–ë–ï–ó torch.interp)
# ============================================================================

class SafeAdvancedAugmentation:
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –±–µ–∑ torch.interp"""
    def __init__(self, p=0.7):  # –£–º–µ–Ω—å—à–∏–ª–∏ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        self.p = p
    
    def __call__(self, sequence):
        if random.random() > self.p:
            return sequence
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–µ–Ω—å—à–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        augmentations = [
            self.safe_temporal_augmentation,
            self.spatial_augmentation,
            self.noise_augmentation,
        ]
        
        num_augs = random.randint(1, 2)  # –ú–µ–Ω—å—à–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        selected_augs = random.sample(augmentations, num_augs)
        
        for aug in selected_augs:
            try:
                sequence = aug(sequence)
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
                continue
        
        return sequence
    
    def safe_temporal_augmentation(self, sequence):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –≤—Ä–µ–º–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –±–µ–∑ torch.interp"""
        seq_len = sequence.shape[0]
        
        # –ü—Ä–æ—Å—Ç–æ–µ temporal cropping –≤–º–µ—Å—Ç–æ interpolation
        if random.random() < 0.3 and seq_len > 20:
            crop_ratio = random.uniform(0.8, 1.0)
            new_length = int(seq_len * crop_ratio)
            start_idx = random.randint(0, seq_len - new_length)
            sequence = sequence[start_idx:start_idx + new_length]
        
        # Temporal dropout (–æ–±–Ω—É–ª–µ–Ω–∏–µ —Å–ª—É—á–∞–π–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤)
        if random.random() < 0.2:
            num_drops = random.randint(1, min(3, seq_len // 10))
            drop_indices = random.sample(range(seq_len), num_drops)
            for idx in drop_indices:
                if idx < sequence.shape[0]:
                    # –ó–∞–º–µ–Ω—è–µ–º –Ω–∞ —Å–æ—Å–µ–¥–Ω–∏–π –∫–∞–¥—Ä –≤–º–µ—Å—Ç–æ –æ–±–Ω—É–ª–µ–Ω–∏—è
                    if idx > 0:
                        sequence[idx] = sequence[idx - 1]
                    elif idx < sequence.shape[0] - 1:
                        sequence[idx] = sequence[idx + 1]
        
        return sequence
    
    def spatial_augmentation(self, sequence):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è"""
        try:
            # Rotation
            if random.random() < 0.3:
                angle = random.uniform(-5, 5) * math.pi / 180  # –ú–µ–Ω—å—à–∏–π —É–≥–æ–ª
                cos_angle, sin_angle = math.cos(angle), math.sin(angle)
                
                x_coords = sequence[..., 0].clone()
                y_coords = sequence[..., 1].clone()
                
                sequence[..., 0] = cos_angle * x_coords - sin_angle * y_coords
                sequence[..., 1] = sin_angle * x_coords + cos_angle * y_coords
            
            # Scaling
            if random.random() < 0.4:
                scale = random.uniform(0.95, 1.05)  # –ú–µ–Ω—å—à–∏–π –º–∞—Å—à—Ç–∞–±
                sequence[..., :2] *= scale
            
            # Translation
            if random.random() < 0.3:
                shift_x = random.uniform(-0.02, 0.02)  # –ú–µ–Ω—å—à–∏–π —Å–¥–≤–∏–≥
                shift_y = random.uniform(-0.02, 0.02)
                sequence[..., 0] += shift_x
                sequence[..., 1] += shift_y
                
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –ø—Ä–æ—Å—Ç—Ä–∞–Ω—Å—Ç–≤–µ–Ω–Ω–æ–π –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {e}")
        
        return sequence
    
    def noise_augmentation(self, sequence):
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ —à—É–º–∞"""
        try:
            if random.random() < 0.5:
                noise_std = random.uniform(0.001, 0.005)  # –ú–µ–Ω—å—à–∏–π —à—É–º
                noise = torch.randn_like(sequence[..., :2]) * noise_std
                sequence[..., :2] += noise
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —à—É–º–∞: {e}")
        
        return sequence

# ============================================================================
# 8. –ë–ï–ó–û–ü–ê–°–ù–´–ô DATASET –ò DATALOADER
# ============================================================================

class SafeFinalASLDataset(Dataset):
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π dataset"""
    def __init__(self, sequences, labels, augment=True):
        self.sequences = sequences
        self.labels = labels
        self.augment = augment
        self.augmentor = SafeAdvancedAugmentation(p=0.6) if augment else None
    
    def __len__(self):
        return len(self.sequences)
    
    def __getitem__(self, idx):
        try:
            sequence = self.sequences[idx].clone()
            label = self.labels[idx]
            
            if self.augment and self.augmentor:
                sequence = self.augmentor(sequence)
            
            return sequence, label
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤ dataset[{idx}]: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç –∫–∞–∫ fallback
            return self.sequences[0].clone(), self.labels[0]

def safe_collate_fn(batch):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–∞—è collate —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        sequences, labels = zip(*batch)
        
        # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑—É–º–Ω—É—é –¥–ª–∏–Ω—É
        lengths = [seq.shape[0] for seq in sequences if seq.shape[0] > 0]
        if not lengths:
            # Fallback –¥–ª—è –ø—É—Å—Ç—ã—Ö sequences
            target_length = 32
        else:
            target_length = int(np.percentile(lengths, 90))
            target_length = min(target_length, 384)
            target_length = max(target_length, 16)  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
        
        padded_sequences = []
        for seq in sequences:
            if seq.shape[0] == 0:
                # –°–æ–∑–¥–∞–µ–º dummy sequence
                seq = torch.zeros(target_length, seq.shape[1], seq.shape[2])
            
            current_length = seq.shape[0]
            
            if current_length > target_length:
                # –û–±—Ä–µ–∑–∞–µ–º
                seq = seq[:target_length]
            elif current_length < target_length:
                # Padding —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–µ–º –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∫–∞–¥—Ä–∞
                padding_length = target_length - current_length
                last_frame = seq[-1:].repeat(padding_length, 1, 1)
                seq = torch.cat([seq, last_frame], dim=0)
            
            padded_sequences.append(seq)
        
        batch_sequences = torch.stack(padded_sequences)
        batch_labels = torch.tensor(labels, dtype=torch.long)
        
        return batch_sequences, batch_labels
    
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –≤ collate_fn: {e}")
        # Fallback: –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π batch
        seq_shape = sequences[0].shape if sequences else (32, 50, 3)
        dummy_sequences = torch.zeros(len(batch), seq_shape[0], seq_shape[1], seq_shape[2])
        dummy_labels = torch.zeros(len(batch), dtype=torch.long)
        return dummy_sequences, dummy_labels

# ============================================================================
# 9. –£–ü–†–û–©–ï–ù–ù–´–ï LOSS –§–£–ù–ö–¶–ò–ò
# ============================================================================

class SimpleFocalLoss(nn.Module):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è Focal Loss"""
    def __init__(self, alpha=1, gamma=2):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
    
    def forward(self, outputs, targets):
        ce_loss = F.cross_entropy(outputs, targets, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        return focal_loss.mean()

class SimpleCombinedLoss(nn.Module):
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω–∞—è loss —Ñ—É–Ω–∫—Ü–∏—è"""
    def __init__(self, ce_weight=0.8, focal_weight=0.2):
        super().__init__()
        self.ce_loss = nn.CrossEntropyLoss(label_smoothing=0.1)
        self.focal_loss = SimpleFocalLoss(alpha=1, gamma=2)
        self.ce_weight = ce_weight
        self.focal_weight = focal_weight
    
    def forward(self, outputs, targets):
        ce = self.ce_loss(outputs, targets)
        focal = self.focal_loss(outputs, targets)
        return self.ce_weight * ce + self.focal_weight * focal

# ============================================================================
# 10. –£–ü–†–û–©–ï–ù–ù–´–ô EMA
# ============================================================================

class SimpleEMA:
    """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è EMA"""
    def __init__(self, model, decay=0.999):
        self.model = model
        self.decay = decay
        self.shadow = {}
        self.backup = {}
        self._initialized = False
    
    def update(self):
        if not self._initialized:
            for name, param in self.model.named_parameters():
                if param.requires_grad:
                    self.shadow[name] = param.data.clone()
            self._initialized = True
        else:
            for name, param in self.model.named_parameters():
                if param.requires_grad and name in self.shadow:
                    self.shadow[name] = self.decay * self.shadow[name] + (1 - self.decay) * param.data
    
    def apply_shadow(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and name in self.shadow:
                self.backup[name] = param.data.clone()
                param.data = self.shadow[name]
    
    def restore(self):
        for name, param in self.model.named_parameters():
            if param.requires_grad and name in self.backup:
                param.data = self.backup[name]

# ============================================================================
# 11. –£–ü–†–û–©–ï–ù–ù–´–ô TRAINER
# ============================================================================

class SafeFinalTrainer:
    """–ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ñ–∏–Ω–∞–ª—å–Ω—ã–π trainer"""
    def __init__(self, model, train_loader, val_loader, num_classes, device):
        self.model = model
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.device = device
        self.num_classes = num_classes
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è loss —Ñ—É–Ω–∫—Ü–∏—è
        self.criterion = SimpleCombinedLoss()
        
        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä
        self.optimizer = AdamW(
            model.parameters(),
            lr=8e-4,  # –ù–µ–º–Ω–æ–≥–æ —É–º–µ–Ω—å—à–∏–ª–∏ LR –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
            weight_decay=0.01,
            betas=(0.9, 0.95)
        )
        
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π EMA
        self.ema = SimpleEMA(model, decay=0.999)
        
        # –ú–µ—Ç—Ä–∏–∫–∏
        self.best_val_acc = 0
        self.history = {'train_loss': [], 'train_acc': [], 'val_loss': [], 'val_acc': []}
    
    def train_epoch(self, epoch):
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        pbar = tqdm(self.train_loader, desc=f'Epoch {epoch}')
        
        for batch_idx, (sequences, labels) in enumerate(pbar):
            try:
                sequences = sequences.to(self.device)
                labels = labels.to(self.device)
                
                self.optimizer.zero_grad()
                
                # Forward pass
                outputs = self.model(sequences)
                loss = self.criterion(outputs, labels)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ loss –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π
                if torch.isnan(loss) or torch.isinf(loss):
                    print(f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π loss –Ω–∞ batch {batch_idx}, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º")
                    continue
                
                # Backward pass
                loss.backward()
                
                # Gradient clipping
                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                
                self.optimizer.step()
                self.ema.update()
                
                # Statistics
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                total += labels.size(0)
                correct += predicted.eq(labels).sum().item()
                
                pbar.set_postfix({
                    'Loss': f'{total_loss/(batch_idx+1):.4f}',
                    'Acc': f'{100.*correct/total:.2f}%'
                })
                
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –≤ batch {batch_idx}: {e}")
                continue
        
        return total_loss / len(self.train_loader), 100. * correct / total
    
    def validate_epoch(self):
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º EMA –º–æ–¥–µ–ª—å –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏
            self.ema.apply_shadow()
            self.model.eval()
            
            total_loss = 0
            correct = 0
            total = 0
            
            with torch.no_grad():
                for sequences, labels in tqdm(self.val_loader, desc='Validation'):
                    try:
                        sequences = sequences.to(self.device)
                        labels = labels.to(self.device)
                        
                        outputs = self.model(sequences)
                        loss = self.criterion(outputs, labels)
                        
                        if not (torch.isnan(loss) or torch.isinf(loss)):
                            total_loss += loss.item()
                            _, predicted = outputs.max(1)
                            total += labels.size(0)
                            correct += predicted.eq(labels).sum().item()
                    except Exception as e:
                        print(f"–û—à–∏–±–∫–∞ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
                        continue
            
            self.ema.restore()
            return total_loss / len(self.val_loader), 100. * correct / total
        
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            self.ema.restore()
            return 0.0, 0.0

# ============================================================================
# 12. –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –ì–õ–ê–í–ù–ê–Ø –§–£–ù–ö–¶–ò–Ø –¢–†–ï–ù–ò–†–û–í–ö–ò
# ============================================================================

def train_safe_final_model(train_data, train_labels, test_data, test_labels, 
                          num_classes, epochs=200, batch_size=24, lr=8e-4):
    """
    –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ñ–∏–Ω–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏
    """
    print("üöÄ –ë–ï–ó–û–ü–ê–°–ù–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø –¢–†–ï–ù–ò–†–û–í–ö–ê ASL –ú–û–î–ï–õ–ò")
    print("=" * 60)
    print("‚ú® –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã:")
    print("   üîß –£–±—Ä–∞–Ω torch.interp (–∑–∞–º–µ–Ω–µ–Ω –Ω–∞ –±–µ–∑–æ–ø–∞—Å–Ω—É—é –≤–µ—Ä—Å–∏—é)")
    print("   üîß –î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤–æ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö")
    print("   üîß –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –Ω–æ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è")
    print("   üîß –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏")
    print("   üîß Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã –¥–ª—è –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö —Ç–æ—á–µ–∫")
    
    try:
        # –°–æ–∑–¥–∞–µ–º datasets
        train_dataset = SafeFinalASLDataset(train_data, train_labels, augment=True)
        test_dataset = SafeFinalASLDataset(test_data, test_labels, augment=False)
        
        # Dataloaders —Å —É–º–µ–Ω—å—à–µ–Ω–Ω—ã–º num_workers –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        train_loader = DataLoader(
            train_dataset, 
            batch_size=batch_size, 
            shuffle=True,
            collate_fn=safe_collate_fn,
            num_workers=0,  # –£–±–∏—Ä–∞–µ–º multiprocessing –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è –æ—à–∏–±–æ–∫
            pin_memory=True
        )
        
        test_loader = DataLoader(
            test_dataset,
            batch_size=batch_size,
            shuffle=False,
            collate_fn=safe_collate_fn,
            num_workers=0,  # –£–±–∏—Ä–∞–µ–º multiprocessing
            pin_memory=True
        )
        
        print(f"‚úÖ Dataloaders —Å–æ–∑–¥–∞–Ω—ã —É—Å–ø–µ—à–Ω–æ")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞
        sample_sequence = train_data[0]
        preprocessor = FinalPreprocessingLayer()
        sample_preprocessed = preprocessor(sample_sequence.unsqueeze(0))
        input_dim = sample_preprocessed.shape[-1]
        
        print(f"\nüìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏:")
        print(f"   –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–∞: {input_dim}")
        print(f"   –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤: {num_classes}")
        print(f"   Batch size: {batch_size}")
        print(f"   Epochs: {epochs}")
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = FinalASLModel(
            input_dim=input_dim,
            num_classes=num_classes,
            max_len=384,
            dim=256,
            num_layers=6  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏
        ).to(device)
        
        # –ü–æ–¥—Å—á–µ—Ç –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤
        total_params = sum(p.numel() for p in model.parameters())
        print(f"   –í—Å–µ–≥–æ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {total_params:,}")
        
        # –°–æ–∑–¥–∞–µ–º trainer
        trainer = SafeFinalTrainer(model, train_loader, test_loader, num_classes, device)
        
        # –ü—Ä–æ—Å—Ç–æ–π scheduler
        scheduler = CosineAnnealingLR(trainer.optimizer, T_max=epochs)
        
        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É...")
        start_time = time.time()
        
        for epoch in range(epochs):
            try:
                # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
                train_loss, train_acc = trainer.train_epoch(epoch)
                
                # –í–∞–ª–∏–¥–∞—Ü–∏—è –∫–∞–∂–¥—ã–µ 10 —ç–ø–æ—Ö –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –≤—Ä–µ–º–µ–Ω–∏
                if epoch % 10 == 0 or epoch == epochs - 1:
                    val_loss, val_acc = trainer.validate_epoch()
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
                    trainer.history['train_loss'].append(train_loss)
                    trainer.history['train_acc'].append(train_acc)
                    trainer.history['val_loss'].append(val_loss)
                    trainer.history['val_acc'].append(val_acc)
                    
                    print(f"\nEpoch {epoch+1}/{epochs}:")
                    print(f"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%")
                    print(f"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%")
                    print(f"  LR: {scheduler.get_last_lr()[0]:.6f}")
                    
                    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                    if val_acc > trainer.best_val_acc:
                        trainer.best_val_acc = val_acc
                        try:
                            torch.save({
                                'epoch': epoch,
                                'model_state_dict': model.state_dict(),
                                'optimizer_state_dict': trainer.optimizer.state_dict(),
                                'val_acc': val_acc,
                                'train_acc': train_acc
                            }, 'models/safe_final_best_asl_model.pth')
                            print(f"  üíæ –ù–æ–≤–∞—è –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å (Val Acc: {val_acc:.2f}%)")
                        except Exception as e:
                            print(f"  ‚ö†Ô∏è –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
                
                # –û–±–Ω–æ–≤–ª—è–µ–º scheduler
                scheduler.step()
                
                # Early stopping –ø—Ä–∏ –ø–ª–æ—Ö–æ–π —Å—Ö–æ–¥–∏–º–æ—Å—Ç–∏
                if epoch > 50 and len(trainer.history['val_acc']) > 5:
                    recent_val_acc = trainer.history['val_acc'][-5:]
                    if all(acc < 10 for acc in recent_val_acc):  # –ï—Å–ª–∏ —Ç–æ—á–Ω–æ—Å—Ç—å —Å–ª–∏—à–∫–æ–º –Ω–∏–∑–∫–∞—è
                        print(f"\n‚ö†Ô∏è Early stopping: –Ω–∏–∑–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å")
                        break
                        
            except Exception as e:
                print(f"–û—à–∏–±–∫–∞ –Ω–∞ —ç–ø–æ—Ö–µ {epoch}: {e}")
                continue
        
        training_time = time.time() - start_time
        print(f"\n‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ –∑–∞ {training_time/3600:.2f} —á–∞—Å–æ–≤")
        print(f"   –õ—É—á—à–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {trainer.best_val_acc:.2f}%")
        
        # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫–∏ –µ—Å–ª–∏ –µ—Å—Ç—å –¥–∞–Ω–Ω—ã–µ
        if trainer.history['val_acc']:
            plot_safe_training_history(trainer.history)
        
        return model, trainer.best_val_acc, trainer.history
        
    except Exception as e:
        print(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –≤ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–µ: {e}")
        return None, 0.0, {}

def plot_safe_training_history(history):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–æ–≤"""
    try:
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))
        
        # –ì—Ä–∞—Ñ–∏–∫ loss
        if history['train_loss'] and history['val_loss']:
            ax1.plot(history['train_loss'], label='Train Loss', color='blue', alpha=0.7)
            ax1.plot(history['val_loss'], label='Val Loss', color='red', alpha=0.7)
            ax1.set_title('Safe Training: Loss')
            ax1.set_xlabel('Validation Steps')
            ax1.set_ylabel('Loss')
            ax1.legend()
            ax1.grid(True, alpha=0.3)
        
        # –ì—Ä–∞—Ñ–∏–∫ accuracy
        if history['train_acc'] and history['val_acc']:
            ax2.plot(history['train_acc'], label='Train Accuracy', color='blue', alpha=0.7)
            ax2.plot(history['val_acc'], label='Val Accuracy', color='red', alpha=0.7)
            ax2.set_title('Safe Training: Accuracy')
            ax2.set_xlabel('Validation Steps')
            ax2.set_ylabel('Accuracy (%)')
            ax2.legend()
            ax2.grid(True, alpha=0.3)
            
            # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å
            max_val_acc = max(history['val_acc'])
            ax2.axhline(y=max_val_acc, color='red', linestyle='--', alpha=0.5)
            ax2.text(0.02, 0.98, f'Best Val Acc: {max_val_acc:.2f}%', 
                    transform=ax2.transAxes, verticalalignment='top',
                    bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        
        plt.tight_layout()
        plt.savefig('safe_final_training_history.png', dpi=300, bbox_inches='tight')
        plt.show()
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤: {e}")

# ============================================================================
# 13. –û–°–ù–û–í–ù–û–ô –ö–û–î –î–õ–Ø –ó–ê–ü–£–°–ö–ê
# ============================================================================

if __name__ == "__main__":
    print("üéØ –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –§–ò–ù–ê–õ–¨–ù–ê–Ø ASL –ú–û–î–ï–õ–¨")
    print("=" * 80)
    
    # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è –º–æ–¥–µ–ª–µ–π
    import os
    os.makedirs("models", exist_ok=True)
    
    print("üîß –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏—è –≤ —ç—Ç–æ–π –≤–µ—Ä—Å–∏–∏:")
    print("   ‚úÖ –£–±—Ä–∞–Ω torch.interp (–∑–∞–º–µ–Ω–µ–Ω –Ω–∞ numpy.interp)")
    print("   ‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫ –≤–æ –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∞—Ö")
    print("   ‚úÖ –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –º–∞—Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ (safe_norm, safe_atan2)")
    print("   ‚úÖ Fallback –º–µ—Ö–∞–Ω–∏–∑–º—ã –≤ preprocessing")
    print("   ‚úÖ –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è –±–µ–∑ –ø—Ä–æ–±–ª–µ–º–Ω—ã—Ö –æ–ø–µ—Ä–∞—Ü–∏–π")
    print("   ‚úÖ num_workers=0 –¥–ª—è –∏–∑–±–µ–∂–∞–Ω–∏—è multiprocessing –æ—à–∏–±–æ–∫")
    print("   ‚úÖ –£–º–µ–Ω—å—à–µ–Ω–Ω—ã–π batch_size –¥–ª—è —Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç–∏")
    print("   ‚úÖ –ü—Ä–æ–≤–µ—Ä–∫–∏ –Ω–∞ NaN/Inf –≤–æ –≤—Å–µ—Ö –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏—Ö –º–µ—Å—Ç–∞—Ö")
    
    print("\nüìà –û–∂–∏–¥–∞–µ–º—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
    print("   üéØ –¢–æ—á–Ω–æ—Å—Ç—å: 65% ‚Üí 75-80% (—Å—Ç–∞–±–∏–ª—å–Ω–æ)")
    print("   ‚ö° –°—Ç–∞–±–∏–ª—å–Ω–∞—è —Å—Ö–æ–¥–∏–º–æ—Å—Ç—å –±–µ–∑ –æ—à–∏–±–æ–∫")
    print("   üõ°Ô∏è –£—Å—Ç–æ–π—á–∏–≤–æ—Å—Ç—å –∫ –ø—Ä–æ–±–ª–µ–º–Ω—ã–º –¥–∞–Ω–Ω—ã–º")
    
    print("\nüöÄ –ì–û–¢–û–í –ö –ó–ê–ü–£–°–ö–£! –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –∫–æ–¥ –Ω–∏–∂–µ:")
    
    # ============================================================================
    # –†–ê–°–ö–û–ú–ú–ï–ù–¢–ò–†–£–ô–¢–ï –î–õ–Ø –ó–ê–ü–£–°–ö–ê:
    # ============================================================================
    
    print("\n# –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ —ç—Ç–∏ —Å—Ç—Ä–æ–∫–∏ –¥–ª—è –∑–∞–ø—É—Å–∫–∞:")
    print("# from step2_prepare_dataset import load_dataset")
    print("# train_data, train_labels, test_data, test_labels, sign_mapping, classes = load_dataset()")
    print("# ")
    print("# model, best_acc, history = train_safe_final_model(")
    print("#     train_data=train_data,")
    print("#     train_labels=train_labels,")
    print("#     test_data=test_data,")
    print("#     test_labels=test_labels,")
    print("#     num_classes=len(classes),")
    print("#     epochs=200,  # –£–º–µ–Ω—å—à–∏–ª–∏ –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ç–µ—Å—Ç–∞")
    print("#     batch_size=24,  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –¥–ª—è RTX 4070")
    print("#     lr=8e-4")
    print("# )")
    
    # –ü–†–ò–ú–ï–† –ò–°–ü–û–õ–¨–ó–û–í–ê–ù–ò–Ø (—Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ):
    
    print("\nüöÄ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ...")
    from step2_prepare_dataset import load_dataset
    train_data, train_labels, test_data, test_labels, sign_mapping, classes = load_dataset(max_samples=None)  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –º–µ–Ω—å—à–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ
    
    print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ:")
    print(f"   –¢—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(train_data)}")
    print(f"   –¢–µ—Å—Ç–æ–≤—ã—Ö –æ–±—Ä–∞–∑—Ü–æ–≤: {len(test_data)}")
    print(f"   –ö–ª–∞—Å—Å–æ–≤: {len(classes)}")
    
    print("\nüöÄ –ó–∞–ø—É—Å–∫–∞–µ–º –±–µ–∑–æ–ø–∞—Å–Ω—É—é —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É...")
    model, best_acc, history = train_safe_final_model(
        train_data=train_data,
        train_labels=train_labels,
        test_data=test_data,
        test_labels=test_labels,
        num_classes=len(classes),
        epochs=200,  # –î–ª—è –ø–µ—Ä–≤–æ–≥–æ —Ç–µ—Å—Ç–∞
        batch_size=24,  # –ö–æ–Ω—Å–µ—Ä–≤–∞—Ç–∏–≤–Ω—ã–π —Ä–∞–∑–º–µ—Ä
        lr=8e-4
    )
    
    if model is not None:
        print(f"\nüéâ –§–ò–ù–ê–õ–¨–ù–´–ï –†–ï–ó–£–õ–¨–¢–ê–¢–´:")
        print(f"   –õ—É—á—à–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å: {best_acc:.2f}%")
        print(f"   –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: models/safe_final_best_asl_model.pth")
    else:
        print("\n‚ùå –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞ –∑–∞–≤–µ—Ä—à–∏–ª–∞—Å—å —Å –æ—à–∏–±–∫–∞–º–∏")
    
    print("\nüéØ –≠—Ç–∞ –≤–µ—Ä—Å–∏—è –¥–æ–ª–∂–Ω–∞ —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ –æ—à–∏–±–æ–∫! üöÄ")