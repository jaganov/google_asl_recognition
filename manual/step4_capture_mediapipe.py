import cv2
import mediapipe as mp
import numpy as np
import torch
import json
import time
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import matplotlib.pyplot as plt
import matplotlib.animation as animation
from mpl_toolkits.mplot3d import Axes3D
from step2_prepare_dataset import load_dataset

class MediaPipeCapture:
    """
    –ö–ª–∞—Å—Å –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∂–µ—Å—Ç–æ–≤ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã —á–µ—Ä–µ–∑ MediaPipe
    """
    
    def __init__(self, 
                 camera_id: int = 0,
                 max_frames: int = 100,
                 fps: int = 30,
                 show_video: bool = True,
                 target_frames: int = 16,  # –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
                 use_only_face: bool = True):  # –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ face landmarks (–∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)
        """
        Args:
            camera_id: ID –∫–∞–º–µ—Ä—ã (–æ–±—ã—á–Ω–æ 0 –¥–ª—è –≤—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π)
            max_frames: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –¥–ª—è –∑–∞–ø–∏—Å–∏
            fps: –ß–∞—Å—Ç–æ—Ç–∞ –∫–∞–¥—Ä–æ–≤ –≤ —Å–µ–∫—É–Ω–¥—É
            show_video: –ü–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ –≤–∏–¥–µ–æ –≤–æ –≤—Ä–µ–º—è –∑–∞–ø–∏—Å–∏
            target_frames: –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ (–∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)
            use_only_face: –ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ face landmarks (–∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)
        """
        self.camera_id = camera_id
        self.max_frames = max_frames
        self.fps = fps
        self.show_video = show_video
        self.target_frames = target_frames
        self.use_only_face = use_only_face
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MediaPipe
        self.mp_holistic = mp.solutions.holistic
        self.mp_drawing = mp.solutions.drawing_utils
        self.mp_drawing_styles = mp.solutions.drawing_styles
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ MediaPipe
        self.holistic = self.mp_holistic.Holistic(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5,
            model_complexity=1
        )
        
        # –•—Ä–∞–Ω–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö
        self.landmarks_data = []
        self.frame_timestamps = []
        
        print(f"üé• MediaPipe Capture –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω:")
        print(f"   –ö–∞–º–µ—Ä–∞: {camera_id}")
        print(f"   –ú–∞–∫—Å–∏–º—É–º –∫–∞–¥—Ä–æ–≤: {max_frames}")
        print(f"   –¶–µ–ª–µ–≤—ã—Ö –∫–∞–¥—Ä–æ–≤: {target_frames}")
        print(f"   FPS: {fps}")
        print(f"   –ü–æ–∫–∞–∑ –≤–∏–¥–µ–æ: {show_video}")
        print(f"   –¢–æ–ª—å–∫–æ face landmarks: {use_only_face} (–∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)")
    
    def start_capture(self) -> Tuple[List[np.ndarray], List[float]]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –∑–∞—Ö–≤–∞—Ç –∂–µ—Å—Ç–æ–≤ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã
        
        Returns:
            landmarks_data: –°–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤ —Å landmarks
            frame_timestamps: –í—Ä–µ–º–µ–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–∞–¥—Ä–æ–≤
        """
        print("\nüé¨ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∂–µ—Å—Ç–æ–≤...")
        print("   –ù–∞–∂–º–∏—Ç–µ 'q' –¥–ª—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∏ –∑–∞–ø–∏—Å–∏")
        print("   –ù–∞–∂–º–∏—Ç–µ 's' –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ç–µ–∫—É—â–µ–≥–æ –∂–µ—Å—Ç–∞")
        
        cap = cv2.VideoCapture(self.camera_id)
        
        if not cap.isOpened():
            print("‚ùå –û—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–∫—Ä—ã—Ç—å –∫–∞–º–µ—Ä—É")
            return [], []
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–∞–º–µ—Ä—ã
        cap.set(cv2.CAP_PROP_FPS, self.fps)
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
        
        self.landmarks_data = []
        self.frame_timestamps = []
        
        start_time = time.time()
        frame_count = 0
        
        try:
            while frame_count < self.max_frames:
                ret, frame = cap.read()
                if not ret:
                    print("‚ùå –û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–¥—Ä–∞")
                    break
                
                # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º BGR –≤ RGB
                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–¥—Ä —á–µ—Ä–µ–∑ MediaPipe
                results = self.holistic.process(rgb_frame)
                
                # –ò–∑–≤–ª–µ–∫–∞–µ–º landmarks
                frame_landmarks = self._extract_landmarks(results)
                
                if frame_landmarks is not None:
                    self.landmarks_data.append(frame_landmarks)
                    self.frame_timestamps.append(time.time() - start_time)
                    frame_count += 1
                
                # –†–∏—Å—É–µ–º landmarks –Ω–∞ –∫–∞–¥—Ä–µ
                annotated_frame = self._draw_landmarks(frame, results)
                
                # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –Ω–∞ –∫–∞–¥—Ä–µ
                cv2.putText(annotated_frame, f"Frames: {frame_count}/{self.max_frames}", 
                           (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
                cv2.putText(annotated_frame, f"Press 'q' to stop, 's' to save", 
                           (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
                
                if self.show_video:
                    cv2.imshow('MediaPipe Capture', annotated_frame)
                
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–ª–∞–≤–∏—à
                key = cv2.waitKey(1) & 0xFF
                if key == ord('q'):
                    print("   –û—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–ø–∏—Å–∏...")
                    break
                elif key == ord('s'):
                    print("   –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∂–µ—Å—Ç–∞...")
                    break
        
        finally:
            cap.release()
            cv2.destroyAllWindows()
        
        print(f"‚úÖ –ó–∞—Ö–≤–∞—Ç –∑–∞–≤–µ—Ä—à–µ–Ω: {len(self.landmarks_data)} –∫–∞–¥—Ä–æ–≤")
        return self.landmarks_data, self.frame_timestamps
    
    def _extract_landmarks(self, results) -> Optional[np.ndarray]:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç landmarks –∏–∑ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ MediaPipe
        
        Args:
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –æ–±—Ä–∞–±–æ—Ç–∫–∏ MediaPipe
            
        Returns:
            landmarks: –ú–∞—Å—Å–∏–≤ landmarks (N, 3) –∏–ª–∏ None
        """
        landmarks = []
        
        if self.use_only_face:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ face landmarks (–∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ)
            if results.face_landmarks:
                for landmark in results.face_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
        else:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ landmarks (face + pose + hands)
            # Face landmarks (468 —Ç–æ—á–µ–∫)
            if results.face_landmarks:
                for landmark in results.face_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
            
            # Pose landmarks (33 —Ç–æ—á–∫–∏)
            if results.pose_landmarks:
                for landmark in results.pose_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
            
            # Left hand landmarks (21 —Ç–æ—á–∫–∞)
            if results.left_hand_landmarks:
                for landmark in results.left_hand_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
            
            # Right hand landmarks (21 —Ç–æ—á–∫–∞)
            if results.right_hand_landmarks:
                for landmark in results.right_hand_landmarks.landmark:
                    landmarks.extend([landmark.x, landmark.y, landmark.z])
        
        if landmarks:
            return np.array(landmarks).reshape(-1, 3)
        return None
    
    def _draw_landmarks(self, frame: np.ndarray, results) -> np.ndarray:
        """
        –†–∏—Å—É–µ—Ç landmarks –Ω–∞ –∫–∞–¥—Ä–µ
        
        Args:
            frame: –ò—Å—Ö–æ–¥–Ω—ã–π –∫–∞–¥—Ä
            results: –†–µ–∑—É–ª—å—Ç–∞—Ç—ã MediaPipe
            
        Returns:
            annotated_frame: –ö–∞–¥—Ä —Å –Ω–∞—Ä–∏—Å–æ–≤–∞–Ω–Ω—ã–º–∏ landmarks
        """
        annotated_frame = frame.copy()
        
        # –†–∏—Å—É–µ–º face landmarks
        if results.face_landmarks:
            self.mp_drawing.draw_landmarks(
                annotated_frame, results.face_landmarks, self.mp_holistic.FACEMESH_CONTOURS,
                landmark_drawing_spec=None,
                connection_drawing_spec=self.mp_drawing_styles.get_default_face_mesh_contours_style()
            )
        
        # –†–∏—Å—É–µ–º pose landmarks (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ face)
        if not self.use_only_face and results.pose_landmarks:
            self.mp_drawing.draw_landmarks(
                annotated_frame, results.pose_landmarks, self.mp_holistic.POSE_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_pose_landmarks_style()
            )
        
        # –†–∏—Å—É–µ–º left hand landmarks (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ face)
        if not self.use_only_face and results.left_hand_landmarks:
            self.mp_drawing.draw_landmarks(
                annotated_frame, results.left_hand_landmarks, self.mp_holistic.HAND_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_hand_landmarks_style(),
                connection_drawing_spec=self.mp_drawing_styles.get_default_hand_connections_style()
            )
        
        # –†–∏—Å—É–µ–º right hand landmarks (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ face)
        if not self.use_only_face and results.right_hand_landmarks:
            self.mp_drawing.draw_landmarks(
                annotated_frame, results.right_hand_landmarks, self.mp_holistic.HAND_CONNECTIONS,
                landmark_drawing_spec=self.mp_drawing_styles.get_default_hand_landmarks_style(),
                connection_drawing_spec=self.mp_drawing_styles.get_default_hand_connections_style()
            )
        
        return annotated_frame
    
    def normalize_landmarks(self, landmarks_data: List[np.ndarray]) -> List[np.ndarray]:
        """
        –ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç landmarks –∫ —Ñ–æ—Ä–º–∞—Ç—É –¥–∞—Ç–∞—Å–µ—Ç–∞
        
        Args:
            landmarks_data: –°–ø–∏—Å–æ–∫ –∫–∞–¥—Ä–æ–≤ —Å landmarks
            
        Returns:
            normalized_data: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        """
        if not landmarks_data:
            return []
        
        print(f"üîÑ –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è landmarks:")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤: {len(landmarks_data)}")
        print(f"   –ò—Å—Ö–æ–¥–Ω—ã—Ö landmarks –Ω–∞ –∫–∞–¥—Ä: {len(landmarks_data[0]) if landmarks_data else 0}")
        
        # 1. –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
        if len(landmarks_data) > self.target_frames:
            # –í—ã–±–∏—Ä–∞–µ–º —Ä–∞–≤–Ω–æ–º–µ—Ä–Ω–æ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –∫–∞–¥—Ä—ã
            indices = np.linspace(0, len(landmarks_data) - 1, self.target_frames, dtype=int)
            landmarks_data = [landmarks_data[i] for i in indices]
            print(f"   –û–≥—Ä–∞–Ω–∏—á–µ–Ω–æ –¥–æ {self.target_frames} –∫–∞–¥—Ä–æ–≤")
        
        # 2. –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ landmarks
        if self.use_only_face:
            expected_landmarks = 468  # Face landmarks (–∫–∞–∫ –≤ —Å—Ç–∞—Ä–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç–∞)
            print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ face landmarks: {expected_landmarks} —Ç–æ—á–µ–∫")
        else:
            # Face (468) + Pose (33) + Left Hand (21) + Right Hand (21) = 543
            expected_landmarks = 543  # –ü–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä landmarks (–∫–∞–∫ –≤ –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ)
            print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ landmarks: {expected_landmarks} —Ç–æ—á–µ–∫")
            print(f"     - Face: 468 (0-467)")
            print(f"     - Pose: 33 (468-500)") 
            print(f"     - Left Hand: 21 (501-521)")
            print(f"     - Right Hand: 21 (522-542)")
        
        # 3. –ü—Ä–∏–≤–æ–¥–∏–º –∫ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º—É –∫–æ–ª–∏—á–µ—Å—Ç–≤—É landmarks
        normalized_data = []
        for frame in landmarks_data:
            if len(frame) >= expected_landmarks:
                # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ expected_landmarks —Ç–æ—á–µ–∫
                normalized_frame = frame[:expected_landmarks]
            else:
                # –î–æ–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏ –µ—Å–ª–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫
                normalized_frame = np.zeros((expected_landmarks, 3))
                normalized_frame[:len(frame)] = frame
            
            normalized_data.append(normalized_frame)
        
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö –∫–∞–¥—Ä–æ–≤: {len(normalized_data)}")
        print(f"   –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã—Ö landmarks –Ω–∞ –∫–∞–¥—Ä: {len(normalized_data[0])}")
        
        return normalized_data
    
    def convert_to_dataset_format(self) -> torch.Tensor:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞
        
        Returns:
            tensor: –¢–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º (frames, landmarks, 3) –≤ —Ñ–æ—Ä–º–∞—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç–∞
        """
        if not self.landmarks_data:
            return torch.empty(0, 0, 3)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
        normalized_data = self.normalize_landmarks(self.landmarks_data)
        
        if not normalized_data:
            return torch.empty(0, 0, 3)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
        tensor = torch.tensor(normalized_data, dtype=torch.float32)
        
        print(f"‚úÖ –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä–æ–≤–∞–Ω–æ –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞: {tensor.shape}")
        return tensor
    
    def save_gesture(self, filename: str = "captured_gesture.json") -> None:
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π –∂–µ—Å—Ç –≤ JSON —Ñ–∞–π–ª
        
        Args:
            filename: –ò–º—è —Ñ–∞–π–ª–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        """
        if not self.landmarks_data:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è")
            return
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ
        normalized_data = self.normalize_landmarks(self.landmarks_data)
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        gesture_data = {
            'frames': len(normalized_data),
            'landmarks_per_frame': len(normalized_data[0]) if normalized_data else 0,
            'timestamps': self.frame_timestamps[:len(normalized_data)],
            'landmarks': [frame.tolist() for frame in normalized_data],
            'dataset_format': True,
            'target_frames': self.target_frames,
            'use_only_face': self.use_only_face
        }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
        with open(filename, 'w') as f:
            json.dump(gesture_data, f, indent=2)
        
        print(f"‚úÖ –ñ–µ—Å—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤ {filename}")
        print(f"   –ö–∞–¥—Ä–æ–≤: {len(normalized_data)}")
        print(f"   Landmarks –Ω–∞ –∫–∞–¥—Ä: {len(normalized_data[0]) if normalized_data else 0}")
        print(f"   –§–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞: {gesture_data['dataset_format']}")
    
    def convert_to_tensor(self) -> torch.Tensor:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ —Ç–µ–Ω–∑–æ—Ä (—É—Å—Ç–∞—Ä–µ–≤—à–∏–π –º–µ—Ç–æ–¥)
        
        Returns:
            tensor: –¢–µ–Ω–∑–æ—Ä —Ä–∞–∑–º–µ—Ä–æ–º (frames, landmarks, 3)
        """
        return self.convert_to_dataset_format()

def visualize_comparison(captured_tensor: torch.Tensor, 
                        dataset_tensor: torch.Tensor,
                        captured_title: str = "–ó–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π –∂–µ—Å—Ç",
                        dataset_title: str = "–ñ–µ—Å—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞",
                        figsize: Tuple[int, int] = (20, 8)) -> None:
    """
    –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω–æ–≥–æ –∂–µ—Å—Ç–∞ —Å –∂–µ—Å—Ç–æ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    """
    fig = plt.figure(figsize=figsize)
    
    # –ì—Ä–∞—Ñ–∏–∫ –∑–∞—Ö–≤–∞—á–µ–Ω–Ω–æ–≥–æ –∂–µ—Å—Ç–∞
    ax1 = fig.add_subplot(1, 2, 1, projection='3d')
    captured_data = captured_tensor.numpy()
    
    if len(captured_data) > 0:
        # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        valid_mask = ~np.isnan(captured_data).any(axis=2)
        valid_frames = []
        for frame in captured_data:
            valid_frame = frame[~np.isnan(frame).any(axis=1)]
            if len(valid_frame) > 0:
                valid_frames.append(valid_frame)
        
        if valid_frames:
            all_points = np.vstack(valid_frames)
            x_min, x_max = all_points[:, 0].min(), all_points[:, 0].max()
            y_min, y_max = all_points[:, 1].min(), all_points[:, 1].max()
            z_min, z_max = all_points[:, 2].min(), all_points[:, 2].max()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
            x_margin = (x_max - x_min) * 0.1
            y_margin = (y_max - y_min) * 0.1
            z_margin = (z_max - z_min) * 0.1
            
            ax1.set_xlim(x_min - x_margin, x_max + x_margin)
            ax1.set_ylim(y_min - y_margin, y_max + y_margin)
            ax1.set_zlim(z_min - z_margin, z_max + z_margin)
            
            # –†–∏—Å—É–µ–º —Ç–æ—á–∫–∏
            ax1.scatter(all_points[:, 0], all_points[:, 1], all_points[:, 2], 
                       c='blue', s=20, alpha=0.7, label=f'Landmarks ({len(all_points)} —Ç–æ—á–µ–∫)')
    
    ax1.set_xlabel('X –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax1.set_ylabel('Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax1.set_zlabel('Z –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax1.set_title(f"{captured_title}\n–ö–∞–¥—Ä–æ–≤: {len(captured_data)}")
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    ax1.set_box_aspect([1, 1, 1])
    
    # –ì—Ä–∞—Ñ–∏–∫ –∂–µ—Å—Ç–∞ –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    ax2 = fig.add_subplot(1, 2, 2, projection='3d')
    dataset_data = dataset_tensor.numpy()
    
    if len(dataset_data) > 0:
        # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
        valid_mask = ~np.isnan(dataset_data).any(axis=2)
        valid_frames = []
        for frame in dataset_data:
            valid_frame = frame[~np.isnan(frame).any(axis=1)]
            if len(valid_frame) > 0:
                valid_frames.append(valid_frame)
        
        if valid_frames:
            all_points = np.vstack(valid_frames)
            x_min, x_max = all_points[:, 0].min(), all_points[:, 0].max()
            y_min, y_max = all_points[:, 1].min(), all_points[:, 1].max()
            z_min, z_max = all_points[:, 2].min(), all_points[:, 2].max()
            
            # –î–æ–±–∞–≤–ª—è–µ–º –æ—Ç—Å—Ç—É–ø—ã
            x_margin = (x_max - x_min) * 0.1
            y_margin = (y_max - y_min) * 0.1
            z_margin = (z_max - z_min) * 0.1
            
            ax2.set_xlim(x_min - x_margin, x_max + x_margin)
            ax2.set_ylim(y_min - y_margin, y_max + y_margin)
            ax2.set_zlim(z_min - z_margin, z_max + z_margin)
            
            # –†–∏—Å—É–µ–º —Ç–æ—á–∫–∏
            ax2.scatter(all_points[:, 0], all_points[:, 1], all_points[:, 2], 
                       c='red', s=20, alpha=0.7, label=f'Landmarks ({len(all_points)} —Ç–æ—á–µ–∫)')
    
    ax2.set_xlabel('X –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax2.set_ylabel('Y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax2.set_zlabel('Z –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞')
    ax2.set_title(f"{dataset_title}\n–ö–∞–¥—Ä–æ–≤: {len(dataset_data)}")
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    ax2.set_box_aspect([1, 1, 1])
    
    plt.tight_layout()
    plt.show()

def analyze_similarity(captured_tensor: torch.Tensor, 
                      dataset_tensor: torch.Tensor) -> Dict[str, float]:
    """
    –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ö–æ–¥—Å—Ç–≤–æ –º–µ–∂–¥—É –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–º –∂–µ—Å—Ç–æ–º –∏ –∂–µ—Å—Ç–æ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞
    
    Returns:
        similarity_metrics: –°–ª–æ–≤–∞—Ä—å —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ —Å—Ö–æ–¥—Å—Ç–≤–∞
    """
    print("\nüìä –ê–Ω–∞–ª–∏–∑ —Å—Ö–æ–¥—Å—Ç–≤–∞ –∂–µ—Å—Ç–æ–≤:")
    
    captured_data = captured_tensor.numpy()
    dataset_data = dataset_tensor.numpy()
    
    if len(captured_data) == 0 or len(dataset_data) == 0:
        print("‚ùå –ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return {}
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä—ã —Ç–µ–Ω–∑–æ—Ä–æ–≤
    print(f"   –ó–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π –∂–µ—Å—Ç: {captured_tensor.shape}")
    print(f"   –ñ–µ—Å—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset_tensor.shape}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ñ–æ—Ä–º–∞—Ç–æ–≤
    if captured_tensor.shape[1] != dataset_tensor.shape[1]:
        print(f"   ‚ö†Ô∏è –†–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ landmarks: {captured_tensor.shape[1]} vs {dataset_tensor.shape[1]}")
    else:
        print(f"   ‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ landmarks —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {captured_tensor.shape[1]}")
    
    if captured_tensor.shape[0] != dataset_tensor.shape[0]:
        print(f"   ‚ö†Ô∏è –†–∞–∑–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤: {captured_tensor.shape[0]} vs {dataset_tensor.shape[0]}")
    else:
        print(f"   ‚úÖ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ —Å–æ–≤–ø–∞–¥–∞–µ—Ç: {captured_tensor.shape[0]}")
    
    # –£–±–∏—Ä–∞–µ–º NaN –∑–Ω–∞—á–µ–Ω–∏—è
    captured_valid = []
    for frame in captured_data:
        valid_frame = frame[~np.isnan(frame).any(axis=1)]
        if len(valid_frame) > 0:
            captured_valid.append(valid_frame)
    
    dataset_valid = []
    for frame in dataset_data:
        valid_frame = frame[~np.isnan(frame).any(axis=1)]
        if len(valid_frame) > 0:
            dataset_valid.append(valid_frame)
    
    if not captured_valid or not dataset_valid:
        print("‚ùå –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        return {}
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç
    captured_all = np.vstack(captured_valid)
    dataset_all = np.vstack(dataset_valid)
    
    captured_ranges = {
        'x': (captured_all[:, 0].min(), captured_all[:, 0].max()),
        'y': (captured_all[:, 1].min(), captured_all[:, 1].max()),
        'z': (captured_all[:, 2].min(), captured_all[:, 2].max())
    }
    
    dataset_ranges = {
        'x': (dataset_all[:, 0].min(), dataset_all[:, 0].max()),
        'y': (dataset_all[:, 1].min(), dataset_all[:, 1].max()),
        'z': (dataset_all[:, 2].min(), dataset_all[:, 2].max())
    }
    
    print(f"   –î–∏–∞–ø–∞–∑–æ–Ω—ã –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç:")
    for coord in ['x', 'y', 'z']:
        print(f"     {coord.upper()}: –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π {captured_ranges[coord][0]:.3f}-{captured_ranges[coord][1]:.3f}, "
              f"–¥–∞—Ç–∞—Å–µ—Ç {dataset_ranges[coord][0]:.3f}-{dataset_ranges[coord][1]:.3f}")
    
    # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤
    range_similarity = 0
    for coord in ['x', 'y', 'z']:
        captured_range = captured_ranges[coord][1] - captured_ranges[coord][0]
        dataset_range = dataset_ranges[coord][1] - dataset_ranges[coord][0]
        
        if captured_range > 0 and dataset_range > 0:
            min_range = min(captured_range, dataset_range)
            max_range = max(captured_range, dataset_range)
            range_similarity += min_range / max_range
    
    range_similarity /= 3
    
    print(f"   –°—Ö–æ–¥—Å—Ç–≤–æ –¥–∏–∞–ø–∞–∑–æ–Ω–æ–≤: {range_similarity:.3f}")
    
    # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤
    frame_similarity = min(len(captured_valid), len(dataset_valid)) / max(len(captured_valid), len(dataset_valid))
    print(f"   –°—Ö–æ–¥—Å—Ç–≤–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–æ–≤: {frame_similarity:.3f}")
    
    # –°—Ö–æ–¥—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤ (—Ä–∞–∑–º–µ—Ä–æ–≤ —Ç–µ–Ω–∑–æ—Ä–æ–≤)
    format_similarity = 0
    if captured_tensor.shape[1] == dataset_tensor.shape[1]:
        format_similarity += 0.5  # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ landmarks
    if captured_tensor.shape[0] == dataset_tensor.shape[0]:
        format_similarity += 0.5  # –°–æ–≤–ø–∞–¥–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤
    
    print(f"   –°—Ö–æ–¥—Å—Ç–≤–æ —Ñ–æ—Ä–º–∞—Ç–æ–≤: {format_similarity:.3f}")
    
    # –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞
    overall_similarity = (range_similarity + frame_similarity + format_similarity) / 3
    print(f"   –û–±—â–µ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {overall_similarity:.3f}")
    
    if overall_similarity > 0.7:
        print("   ‚úÖ –ñ–µ—Å—Ç—ã –ø–æ—Ö–æ–∂–∏!")
    elif overall_similarity > 0.4:
        print("   ‚ö†Ô∏è –ñ–µ—Å—Ç—ã —á–∞—Å—Ç–∏—á–Ω–æ –ø–æ—Ö–æ–∂–∏")
    else:
        print("   ‚ùå –ñ–µ—Å—Ç—ã —Å–∏–ª—å–Ω–æ –æ—Ç–ª–∏—á–∞—é—Ç—Å—è")
    
    return {
        'range_similarity': range_similarity,
        'frame_similarity': frame_similarity,
        'format_similarity': format_similarity,
        'overall_similarity': overall_similarity
    }

# –ü—Ä–∏–º–µ—Ä—ã –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
if __name__ == "__main__":
    print("üé• –ó–∞—Ö–≤–∞—Ç –∂–µ—Å—Ç–æ–≤ —Å –≤–µ–±-–∫–∞–º–µ—Ä—ã")
    print("=" * 50)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    print("üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è...")
    train_data, train_labels, test_data, test_labels, sign_mapping, classes = load_dataset(max_samples=5)
    
    if not train_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç")
        exit()
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞—Ö–≤–∞—Ç—á–∏–∫ —Å –Ω–∞—Å—Ç—Ä–æ–π–∫–∞–º–∏ –¥–ª—è –¥–∞—Ç–∞—Å–µ—Ç–∞
    print("üéØ –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∑–∞—Ö–≤–∞—Ç–∞:")
    print("   - target_frames=16: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–∞–¥—Ä–æ–≤ –∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ")
    print("   - use_only_face=False: –≤—Å–µ landmarks (543 —Ç–æ—á–∫–∏) - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç")
    print("   - use_only_face=True: —Ç–æ–ª—å–∫–æ face landmarks (468 —Ç–æ—á–µ–∫) - —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç")
    
    capture = MediaPipeCapture(
        camera_id=0,
        max_frames=50,
        fps=15,
        show_video=True,
        target_frames=16,  # –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–∞–¥—Ä–æ–≤ –∫–∞–∫ –≤ –¥–∞—Ç–∞—Å–µ—Ç–µ
        use_only_face=False  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ landmarks (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç)
    )
    
    # –ó–∞—Ö–≤–∞—Ç—ã–≤–∞–µ–º –∂–µ—Å—Ç
    print("\nüé¨ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞—Ö–≤–∞—Ç –∂–µ—Å—Ç–∞...")
    landmarks_data, timestamps = capture.start_capture()
    
    if not landmarks_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞—Ö–≤–∞—Ç–∏—Ç—å –∂–µ—Å—Ç")
        exit()
    
    # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Ç–µ–Ω–∑–æ—Ä
    captured_tensor = capture.convert_to_dataset_format()
    print(f"‚úÖ –ó–∞—Ö–≤–∞—á–µ–Ω –∂–µ—Å—Ç: {captured_tensor.shape}")
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∂–µ—Å—Ç
    capture.save_gesture("my_gesture.json")
    
    # –í—ã–±–∏—Ä–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–π –∂–µ—Å—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞ –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    import random
    random_idx = random.randint(0, len(train_data) - 1)
    dataset_tensor = train_data[random_idx]
    dataset_label = train_labels[random_idx]
    
    # –°–æ–∑–¥–∞–µ–º –æ–±—Ä–∞—Ç–Ω—ã–π –º–∞–ø–ø–∏–Ω–≥
    reverse_mapping = {v: k for k, v in sign_mapping.items()}
    dataset_sign_name = reverse_mapping[dataset_label]
    
    print(f"\nüîÑ –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º —Å –∂–µ—Å—Ç–æ–º –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞:")
    print(f"   –ó–Ω–∞–∫: '{dataset_sign_name}' (–º–µ—Ç–∫–∞: {dataset_label})")
    print(f"   –†–∞–∑–º–µ—Ä: {dataset_tensor.shape}")
    
    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ö–æ–¥—Å—Ç–≤–æ
    similarity_metrics = analyze_similarity(captured_tensor, dataset_tensor)
    
    # –í–∏–∑—É–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ
    print("\nüñºÔ∏è –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è:")
    visualize_comparison(
        captured_tensor, 
        dataset_tensor,
        captured_title="–í–∞—à –∑–∞—Ö–≤–∞—á–µ–Ω–Ω—ã–π –∂–µ—Å—Ç",
        dataset_title=f"–ñ–µ—Å—Ç –∏–∑ –¥–∞—Ç–∞—Å–µ—Ç–∞: {dataset_sign_name}"
    )
    
    print("\n‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω!")
    print("üí° –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ñ—É–Ω–∫—Ü–∏–∏:")
    print("   - MediaPipeCapture() - –¥–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –∂–µ—Å—Ç–æ–≤")
    print("   - analyze_similarity() - –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞")
    print("   - visualize_comparison() - –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
    print("\nüéØ –î–ª—è –∑–∞—Ö–≤–∞—Ç–∞ –Ω–æ–≤–æ–≥–æ –∂–µ—Å—Ç–∞:")
    print("   # –° –ø–æ–ª–Ω—ã–º –Ω–∞–±–æ—Ä–æ–º landmarks (543 —Ç–æ—á–∫–∏) - –†–ï–ö–û–ú–ï–ù–î–£–ï–¢–°–Ø:")
    print("   capture = MediaPipeCapture(target_frames=16, use_only_face=False)")
    print("   landmarks, timestamps = capture.start_capture()")
    print("   tensor = capture.convert_to_dataset_format()")
    print("\n   # –¢–æ–ª—å–∫–æ face landmarks (468 —Ç–æ—á–µ–∫) - —Å—Ç–∞—Ä—ã–π —Ñ–æ—Ä–º–∞—Ç:")
    print("   capture = MediaPipeCapture(target_frames=16, use_only_face=True)")
    print("   landmarks, timestamps = capture.start_capture()")
    print("   tensor = capture.convert_to_dataset_format()")
    print("\nüìä –ù–æ–≤—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:")
    print("   - target_frames: –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ –∫–∞–¥—Ä–æ–≤")
    print("   - use_only_face: –≤—ã–±–æ—Ä —Ç–∏–ø–∞ landmarks")
    print("   - convert_to_dataset_format(): –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç–∞—Å–µ—Ç–∞")
    print("   - normalize_landmarks(): –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
    print("\nüí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:")
    print("   - –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Ç–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –≤—Å–µ landmarks (543 —Ç–æ—á–∫–∏)")
    print("   - –°—Ç—Ä—É–∫—Ç—É—Ä–∞: Face(468) + Pose(33) + Left Hand(21) + Right Hand(21)")
    print("   - –î–ª—è —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è –∂–µ—Å—Ç–æ–≤ —Ä—É–∫ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ use_only_face=False")
