# preprocessing.py
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from typing import Optional, List, Dict, Tuple
from pathlib import Path

class ASLPreprocessor(nn.Module):
    """PyTorch –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è Google ASL Signs dataset"""
    
    def __init__(self, 
                 max_len: int = 384,
                 point_landmarks: Optional[List[int]] = None):
        super().__init__()
        self.max_len = max_len
        
        # –í–∞–∂–Ω—ã–µ landmark —Ç–æ—á–∫–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        if point_landmarks is None:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–æ—á–∫–∏ (–∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è, –Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ)
            # –í —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —É –Ω–∞—Å –º–µ–Ω—å—à–µ —Ç–æ—á–µ–∫, –ø–æ—ç—Ç–æ–º—É –±–µ—Ä–µ–º –≤—Å–µ
            self.point_landmarks = None  # –ë—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –≤—Å–µ —Ç–æ—á–∫–∏
        else:
            self.point_landmarks = point_landmarks
            
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ –±—É–¥–µ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –ø–µ—Ä–≤–æ–≥–æ —Ñ–∞–π–ª–∞
        self.total_landmarks = None
        
        # –ö—ç—à –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö —Ñ–∞–π–ª–æ–≤ (–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ —É—Å–∫–æ—Ä—è–µ—Ç –∑–∞–≥—Ä—É–∑–∫—É)
        self._file_cache = {}
        self._cache_hits = 0
        self._cache_misses = 0
        self._max_cache_size = 1000  # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
        
        print(f"üéØ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ):")
        print(f"   –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {max_len}")
        print(f"   –ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ —Ç–æ—á–∫–∏: –≤—Å–µ –¥–æ—Å—Ç—É–ø–Ω—ã–µ")
        print(f"   –ö—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–æ–≤: –≤–∫–ª—é—á–µ–Ω–æ (–º–∞–∫—Å. {self._max_cache_size} —Ñ–∞–π–ª–æ–≤)")
    

    
    def load_landmark_file(self, file_path: str) -> torch.Tensor:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç landmark —Ñ–∞–π–ª –∏ –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –≤ —Ç–µ–Ω–∑–æ—Ä (—Å –∫—ç—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º)
        Input: –ø—É—Ç—å –∫ parquet —Ñ–∞–π–ª—É
        Output: (frames, landmarks, 3) - –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã x, y, z
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
        if file_path in self._file_cache:
            self._cache_hits += 1
            return self._file_cache[file_path]
        
        self._cache_misses += 1
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º parquet —Ñ–∞–π–ª
        df = pd.read_parquet(file_path)
        
        # –ü–æ–ª—É—á–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–∞–¥—Ä—ã –∏ —Å–æ—Ä—Ç–∏—Ä—É–µ–º –∏—Ö
        frames = sorted(df['frame'].unique())
        
        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ landmark_index
        all_landmarks = sorted(df['landmark_index'].unique())
        
        # –ï—Å–ª–∏ —ç—Ç–æ –ø–µ—Ä–≤—ã–π —Ñ–∞–π–ª, —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º total_landmarks
        if self.total_landmarks is None:
            self.total_landmarks = len(all_landmarks)
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è
            if not hasattr(ASLPreprocessor, '_landmarks_printed'):
                print(f"   –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ landmark —Ç–æ—á–µ–∫: {self.total_landmarks}")
                print(f"   (–≠—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ –≤—ã–≤–æ–¥–∏—Ç—Å—è —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω —Ä–∞–∑)")
                ASLPreprocessor._landmarks_printed = True
            else:
                # –ï—Å–ª–∏ —Ñ–ª–∞–≥ —É–∂–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, –ø—Ä–æ—Å—Ç–æ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º total_landmarks –±–µ–∑ –≤—ã–≤–æ–¥–∞
                pass
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤—Å–µ—Ö landmarks
        # –†–∞–∑–º–µ—Ä: (frames, total_landmarks, 3)
        landmarks_tensor = torch.full((len(frames), self.total_landmarks, 3), 
                                    float('nan'), dtype=torch.float32)
        
        # –ó–∞–ø–æ–ª–Ω—è–µ–º —Ç–µ–Ω–∑–æ—Ä –¥–∞–Ω–Ω—ã–º–∏
        for frame_idx, frame in enumerate(frames):
            # –î–∞–Ω–Ω—ã–µ –¥–ª—è —Ç–µ–∫—É—â–µ–≥–æ –∫–∞–¥—Ä–∞
            frame_data = df[df['frame'] == frame]
            
            for landmark_idx, point_idx in enumerate(all_landmarks):
                # –ò—â–µ–º —Ç–æ—á–∫—É —Å –Ω—É–∂–Ω—ã–º –∏–Ω–¥–µ–∫—Å–æ–º
                point_data = frame_data[frame_data['landmark_index'] == point_idx]
                
                if len(point_data) > 0:
                    # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—É—é –Ω–∞–π–¥–µ–Ω–Ω—É—é —Ç–æ—á–∫—É
                    coords = point_data[['x', 'y', 'z']].iloc[0].values
                    landmarks_tensor[frame_idx, landmark_idx] = torch.tensor(coords)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (—Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º —Ä–∞–∑–º–µ—Ä–∞)
        if len(self._file_cache) < self._max_cache_size:
            self._file_cache[file_path] = landmarks_tensor
        else:
            # –ï—Å–ª–∏ –∫—ç—à –ø–æ–ª–Ω—ã–π, —É–¥–∞–ª—è–µ–º —Å–∞–º—ã–π —Å—Ç–∞—Ä—ã–π —ç–ª–µ–º–µ–Ω—Ç
            oldest_key = next(iter(self._file_cache))
            del self._file_cache[oldest_key]
            self._file_cache[file_path] = landmarks_tensor
        
        return landmarks_tensor
    
    def forward(self, x):
        """
        –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥ landmarks (–∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è)
        Input: (batch, frames, landmarks, channels) 
        Output: (batch, frames, features)
        """
        batch_size, frames, landmarks, channels = x.shape
        
        # 1. –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø–æ —Ü–µ–Ω—Ç—Ä—É –∫–∞–¥—Ä–∞ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—Ä–µ–¥–Ω–µ–µ –ø–æ –≤—Å–µ–º —Ç–æ—á–∫–∞–º –∫–∞–∫ —Ä–µ—Ñ–µ—Ä–µ–Ω—Å
        nose_mean = torch.mean(x[:, :, :, :2], dim=(1,2), keepdim=True)
        nose_mean = torch.where(torch.isnan(nose_mean), 
                              torch.tensor(0.5, device=x.device, dtype=x.dtype), 
                              nose_mean)
        
        # 2. –ò—Å–ø–æ–ª—å–∑—É–µ–º –≤—Å–µ landmark —Ç–æ—á–∫–∏ (–∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞–Ω–æ –ø–æ–¥ —Ä–µ–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ)
        x_selected = x
        
        # 3. –°—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∞—Ü–∏—è (–∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è)
        x_coords = x_selected[:, :, :, :2]  # –¢–æ–ª—å–∫–æ x, y –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
        std = torch.std(x_coords, dim=(1,2), keepdim=True, unbiased=False)
        std = torch.where(std < 1e-6, torch.ones_like(std), std)
        
        x_norm = (x_coords - nose_mean) / std
        
        # 4. –û–±—Ä–µ–∑–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        if frames > self.max_len:
            x_norm = x_norm[:, :self.max_len]
            frames = self.max_len
        
        # 5. Motion features (—Ç–æ—á–Ω–æ –∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è)
        # dx = x[t+1] - x[t] (lag1)
        if frames > 1:
            dx = torch.zeros_like(x_norm)
            dx[:, :-1] = x_norm[:, 1:] - x_norm[:, :-1]
        else:
            dx = torch.zeros_like(x_norm)
        
        # dx2 = x[t+2] - x[t] (lag2)
        if frames > 2:
            dx2 = torch.zeros_like(x_norm)
            dx2[:, :-2] = x_norm[:, 2:] - x_norm[:, :-2]
        else:
            dx2 = torch.zeros_like(x_norm)
        
        # 6. –û–±—ä–µ–¥–∏–Ω—è–µ–º –≤—Å–µ —Ñ–∏—á–∏ (–∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è)
        # Flatten landmarks dimension: (batch, frames, landmarks*2)
        x_flat = x_norm.view(batch_size, frames, -1)
        dx_flat = dx.view(batch_size, frames, -1) 
        dx2_flat = dx2.view(batch_size, frames, -1)
        
        # Concatenate: position + velocity + acceleration
        features = torch.cat([x_flat, dx_flat, dx2_flat], dim=-1)
        
        # 7. –ó–∞–º–µ–Ω—è–µ–º NaN –Ω–∞ 0 (–∫–∞–∫ —É –ø–æ–±–µ–¥–∏—Ç–µ–ª—è)
        features = torch.where(torch.isnan(features), 
                             torch.zeros_like(features), 
                             features)
        
        return features
    
    def get_cache_stats(self) -> dict:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫—ç—à–∞"""
        total_requests = self._cache_hits + self._cache_misses
        hit_rate = self._cache_hits / total_requests if total_requests > 0 else 0
        
        return {
            'cache_hits': self._cache_hits,
            'cache_misses': self._cache_misses,
            'hit_rate': hit_rate,
            'cache_size': len(self._file_cache),
            'max_cache_size': self._max_cache_size
        }
    
    def clear_cache(self):
        """–û—á–∏—â–∞–µ—Ç –∫—ç—à"""
        self._file_cache.clear()
        self._cache_hits = 0
        self._cache_misses = 0
        print("üßπ –ö—ç—à –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –æ—á–∏—â–µ–Ω")

class ASLDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è Google ASL Signs"""
    
    def __init__(self, 
                 data_dir: str = "../data/google_asl_signs",
                 max_len: int = 384,
                 batch_size: int = 32,
                 preprocessor: Optional[ASLPreprocessor] = None):
        self.data_dir = Path(data_dir)
        self.max_len = max_len
        self.batch_size = batch_size
        
        if preprocessor is None:
            self.preprocessor = ASLPreprocessor(max_len=max_len)
        else:
            self.preprocessor = preprocessor
            
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        self.train_df = pd.read_csv(self.data_dir / "train.csv")
        self.sign_mapping = self._load_sign_mapping()
        
        print(f"üìä –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.train_df)} –∑–∞–ø–∏—Å–µ–π")
        print(f"üéØ –£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞–∫–æ–≤: {self.train_df['sign'].nunique()}")
    
    def _load_sign_mapping(self) -> Dict[str, int]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–∞–ø–ø–∏–Ω–≥ –∑–Ω–∞–∫–æ–≤ –∫ –∏–Ω–¥–µ–∫—Å–∞–º"""
        with open(self.data_dir / "sign_to_prediction_index_map.json", 'r') as f:
            import json
            return json.load(f)
    
    def load_sequence(self, file_path: str) -> Tuple[torch.Tensor, int]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –æ–¥–Ω—É –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å landmarks
        Returns: (landmarks_tensor, label)
        """
        # –ü–æ–ª–Ω—ã–π –ø—É—Ç—å –∫ —Ñ–∞–π–ª—É
        full_path = self.data_dir / file_path
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º landmarks
        landmarks = self.preprocessor.load_landmark_file(str(full_path))
        
        # –ü–æ–ª—É—á–∞–µ–º –º–µ—Ç–∫—É
        row = self.train_df[self.train_df['path'] == file_path].iloc[0]
        label = self.sign_mapping[row['sign']]
        
        return landmarks, label
    
    def get_batch(self, indices: List[int]) -> Tuple[torch.Tensor, torch.Tensor]:
        """
        –ó–∞–≥—Ä—É–∂–∞–µ—Ç –±–∞—Ç—á –¥–∞–Ω–Ω—ã—Ö
        Returns: (batch_landmarks, batch_labels)
        """
        batch_landmarks = []
        batch_labels = []
        
        for idx in indices:
            file_path = self.train_df.iloc[idx]['path']
            landmarks, label = self.load_sequence(file_path)
            batch_landmarks.append(landmarks)
            batch_labels.append(label)
        
        # –ü–∞–¥–¥–∏–Ω–≥ –¥–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π –¥–ª–∏–Ω—ã –≤ –±–∞—Ç—á–µ
        max_frames = max(landmarks.shape[0] for landmarks in batch_landmarks)
        max_frames = min(max_frames, self.max_len)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–Ω–∑–æ—Ä—ã
        batch_tensor = torch.zeros(len(batch_landmarks), max_frames, 
                                 self.preprocessor.total_landmarks, 3)
        
        for i, landmarks in enumerate(batch_landmarks):
            frames = min(landmarks.shape[0], max_frames)
            batch_tensor[i, :frames] = landmarks[:frames]
        
        batch_labels = torch.tensor(batch_labels, dtype=torch.long)
        
        return batch_tensor, batch_labels

def test_preprocessor():
    """–¢–µ—Å—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏...")
    
    # –°–æ–∑–¥–∞–µ–º –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä
    preprocessor = ASLPreprocessor(max_len=64)
    
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö
    data_loader = ASLDataLoader(preprocessor=preprocessor)
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –Ω–∞ –æ–¥–Ω–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    test_file = data_loader.train_df.iloc[0]['path']
    print(f"üìÅ –¢–µ—Å—Ç–æ–≤—ã–π —Ñ–∞–π–ª: {test_file}")
    
    try:
        landmarks, label = data_loader.load_sequence(test_file)
        print(f"   –ó–∞–≥—Ä—É–∂–µ–Ω–æ landmarks: {landmarks.shape}")
        print(f"   –ú–µ—Ç–∫–∞: {label}")
        
        # –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–∏–Ω–≥
        with torch.no_grad():
            # –î–æ–±–∞–≤–ª—è–µ–º batch dimension
            landmarks_batch = landmarks.unsqueeze(0)
            features = preprocessor(landmarks_batch)
        
        print(f"   Input shape: {landmarks_batch.shape}")
        print(f"   Output shape: {features.shape}")
        print(f"   NaN –≤ output: {torch.isnan(features).sum().item()}")
        print(f"   Output range: [{features.min():.3f}, {features.max():.3f}]")
        
        return features.shape[-1]  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∏—á
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏: {e}")
        return None

if __name__ == "__main__":
    feature_dim = test_preprocessor()
    if feature_dim:
        print(f"‚úÖ –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –≥–æ—Ç–æ–≤! Feature dimension: {feature_dim}")
    else:
        print("‚ùå –û—à–∏–±–∫–∞ –≤ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–µ")