#!/usr/bin/env python3
"""
–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –±–µ–∑ –ª–∏—à–Ω–∏—Ö –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–æ–≤
"""

import torch
import sys
import os
import platform

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

# –ü–æ–¥–∞–≤–ª—è–µ–º –æ—à–∏–±–∫–∏ Triton –Ω–∞ Windows
if platform.system() == 'Windows':
    try:
        import torch._dynamo
        torch._dynamo.config.suppress_errors = True
        print("üîß –ü–æ–¥–∞–≤–ª–µ–Ω—ã –æ—à–∏–±–∫–∏ Triton –¥–ª—è Windows")
    except:
        pass

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ TensorFloat32
if torch.cuda.is_available():
    torch.set_float32_matmul_precision('high')
    print("üîß –í–∫–ª—é—á–µ–Ω TensorFloat32")

# –°–±—Ä–æ—Å —Ñ–ª–∞–≥–∞ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
from preprocessing import ASLPreprocessor
if hasattr(ASLPreprocessor, '_landmarks_printed'):
    delattr(ASLPreprocessor, '_landmarks_printed')

from train import ASLTrainer

def test_quick():
    """–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç"""
    print("üß™ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏...")
    
    try:
        # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        print(f"\n1. –°–∏—Å—Ç–µ–º–∞: {platform.system()}")
        print(f"   ‚úÖ PyTorch –≤–µ—Ä—Å–∏—è: {torch.__version__}")
        print(f"   ‚úÖ CUDA –¥–æ—Å—Ç—É–ø–µ–Ω: {torch.cuda.is_available()}")
        
        if torch.cuda.is_available():
            print(f"   ‚úÖ GPU: {torch.cuda.get_device_name(0)}")
        
        # 2. –¢–µ—Å—Ç —Ç—Ä–µ–Ω–µ—Ä–∞ (—Å–æ–∑–¥–∞–µ—Ç —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä)
        print("\n2. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä...")
        trainer = ASLTrainer(
            data_dir="../data/google_asl_signs",
            model_dir="models/test_quick",
            max_len=32,
            batch_size=2,
            dim=32,
            lr=1e-3,
            epochs=1,
            use_augmentations=True,
            use_mixed_precision=False,  # –û—Ç–∫–ª—é—á–∞–µ–º –¥–ª—è –ø—Ä–æ—Å—Ç–æ—Ç—ã
            gradient_clip_val=1.0,
            gradient_accumulation_steps=1
        )
        
        print(f"   ‚úÖ –¢—Ä–µ–Ω–µ—Ä —Å–æ–∑–¥–∞–Ω")
        print(f"   ‚úÖ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in trainer.model.parameters()):,}")
        
        # 3. –¢–µ—Å—Ç –æ–¥–Ω–æ–≥–æ –±–∞—Ç—á–∞
        print("\n3. –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω –±–∞—Ç—á...")
        trainer.model.train()
        
        batch = next(iter(trainer.train_loader))
        features = batch['features'].to(trainer.device)
        labels = batch['labels'].to(trainer.device)
        
        outputs = trainer.model(features)
        loss = trainer.criterion(outputs, labels)
        
        print(f"   ‚úÖ Forward pass —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   ‚úÖ Loss: {loss.item():.4f}")
        
        # 4. –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏
        print("\n4. –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é...")
        trainer.model.eval()
        with torch.no_grad():
            val_batch = next(iter(trainer.val_loader))
            val_features = val_batch['features'].to(trainer.device)
            val_labels = val_batch['labels'].to(trainer.device)
            val_outputs = trainer.model(val_features)
            val_loss = trainer.criterion(val_outputs, val_labels)
        
        print(f"   ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç")
        print(f"   ‚úÖ Val Loss: {val_loss.item():.4f}")
        
        print("\nüéâ –ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –ø—Ä–æ—à–µ–ª —É—Å–ø–µ—à–Ω–æ!")
        print("‚úÖ –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –æ–±—É—á–µ–Ω–∏—é")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_quick()
    if success:
        print("\nüöÄ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ!")
        print("python train.py")
    else:
        print("\n‚ö†Ô∏è –ù—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏") 