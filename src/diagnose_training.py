# diagnose_training.py
import torch
import torch.nn as nn
import time
import psutil
import os
from pathlib import Path
import numpy as np
from tqdm import tqdm

def check_gpu_usage():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è GPU"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê GPU:")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
        return False
    
    print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–µ–Ω")
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"‚úÖ –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–µ–∫—É—â–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated() / 1024**3
    print(f"üìä –ù–∞—á–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å GPU: {initial_memory:.2f} GB")
    
    return True

def test_data_loading_speed():
    """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîç –¢–ï–°–¢ –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–•:")
    print("=" * 50)
    
    try:
        from data_loader import ASLDataLoader
        
        print("üìÇ –ó–∞–≥—Ä—É–∂–∞–µ–º DataLoader...")
        start_time = time.time()
        
        dataloader = ASLDataLoader(
            data_dir="../data/google_asl_signs",
            batch_size=12,
            max_len=384,
            num_workers=4
        )
        
        load_time = time.time() - start_time
        print(f"‚úÖ DataLoader –∑–∞–≥—Ä—É–∂–µ–Ω –∑–∞ {load_time:.2f} —Å–µ–∫")
        
        # –ü–æ–ª—É—á–∞–µ–º dataloaders
        train_loader, val_loader, test_loader = dataloader.get_dataloaders(augment_train=True)
        
        print(f"‚úÖ Train batches: {len(train_loader)}")
        print(f"‚úÖ Val batches: {len(val_loader)}")
        print(f"‚úÖ Test batches: {len(test_loader)}")
        
        # –¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
        print("\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º —Å–∫–æ—Ä–æ—Å—Ç—å –∑–∞–≥—Ä—É–∑–∫–∏ –±–∞—Ç—á–∞...")
        start_time = time.time()
        
        for i, batch in enumerate(train_loader):
            if i >= 3:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
                break
            batch_time = time.time() - start_time
            print(f"   –ë–∞—Ç—á {i+1}: {batch_time:.2f} —Å–µ–∫")
            start_time = time.time()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä—ã –¥–∞–Ω–Ω—ã—Ö
            features = batch['features']
            labels = batch['labels']
            print(f"   –†–∞–∑–º–µ—Ä features: {features.shape}")
            print(f"   –†–∞–∑–º–µ—Ä labels: {labels.shape}")
            print(f"   –¢–∏–ø features: {features.dtype}")
        
        return train_loader, val_loader, test_loader
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None, None, None

def test_gpu_transfer_speed(train_loader):
    """–¢–µ—Å—Ç —Å–∫–æ—Ä–æ—Å—Ç–∏ –ø–µ—Ä–µ–¥–∞—á–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ GPU"""
    print("\nüîç –¢–ï–°–¢ –ü–ï–†–ï–î–ê–ß–ò –ù–ê GPU:")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("‚ùå GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    device = torch.device('cuda')
    
    # –û—á–∏—â–∞–µ–º –ø–∞–º—è—Ç—å
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated() / 1024**3
    print(f"üìä –ü–∞–º—è—Ç—å –¥–æ –ø–µ—Ä–µ–¥–∞—á–∏: {initial_memory:.2f} GB")
    
    # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–µ–¥–∞—á—É –¥–∞–Ω–Ω—ã—Ö
    for i, batch in enumerate(train_loader):
        if i >= 3:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
            break
            
        start_time = time.time()
        
        # –ü–µ—Ä–µ–¥–∞–µ–º –Ω–∞ GPU
        features = batch['features'].to(device, non_blocking=True)
        labels = batch['labels'].to(device, non_blocking=True)
        
        transfer_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
        current_memory = torch.cuda.memory_allocated() / 1024**3
        cached_memory = torch.cuda.memory_reserved() / 1024**3
        
        print(f"   –ë–∞—Ç—á {i+1}:")
        print(f"     –í—Ä–µ–º—è –ø–µ—Ä–µ–¥–∞—á–∏: {transfer_time:.3f} —Å–µ–∫")
        print(f"     –ü–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞: {current_memory:.2f} GB")
        print(f"     –ü–∞–º—è—Ç—å –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∞: {cached_memory:.2f} GB")
        print(f"     –†–∞–∑–º–µ—Ä features –Ω–∞ GPU: {features.shape}")
        
        # –û—á–∏—â–∞–µ–º –¥–ª—è —Å–ª–µ–¥—É—é—â–µ–≥–æ —Ç–µ—Å—Ç–∞
        del features, labels
        torch.cuda.empty_cache()

def test_model_forward_pass(train_loader):
    """–¢–µ—Å—Ç forward pass –º–æ–¥–µ–ª–∏"""
    print("\nüîç –¢–ï–°–¢ FORWARD PASS:")
    print("=" * 50)
    
    if not torch.cuda.is_available():
        print("‚ùå GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        return
    
    device = torch.device('cuda')
    
    try:
        from models import get_model
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
        sample_batch = next(iter(train_loader))
        input_dim = sample_batch['features'].shape[-1]
        
        print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {input_dim}")
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        model = get_model(
            input_dim=input_dim,
            num_classes=250,  # –ü—Ä–∏–º–µ—Ä–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∫–ª–∞—Å—Å–æ–≤
            max_len=384,
            dim=192
        ).to(device)
        
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞")
        print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–æ–¥–µ–ª–∏: {sum(p.numel() for p in model.parameters()):,}")
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º forward pass
        model.train()
        torch.cuda.empty_cache()
        
        for i, batch in enumerate(train_loader):
            if i >= 3:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 3 –±–∞—Ç—á–∞
                break
                
            features = batch['features'].to(device, non_blocking=True)
            labels = batch['labels'].to(device, non_blocking=True)
            
            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è forward pass
            torch.cuda.synchronize()
            start_time = time.time()
            
            with torch.no_grad():  # –î–ª—è —Ç–µ—Å—Ç–∞ —Å–∫–æ—Ä–æ—Å—Ç–∏
                outputs = model(features)
            
            torch.cuda.synchronize()
            forward_time = time.time() - start_time
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
            current_memory = torch.cuda.memory_allocated() / 1024**3
            cached_memory = torch.cuda.memory_reserved() / 1024**3
            
            print(f"   –ë–∞—Ç—á {i+1}:")
            print(f"     Forward pass: {forward_time:.3f} —Å–µ–∫")
            print(f"     –ü–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞: {current_memory:.2f} GB")
            print(f"     –ü–∞–º—è—Ç—å –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∞: {cached_memory:.2f} GB")
            print(f"     –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–æ–≤: {outputs.shape}")
            
            # –û—á–∏—â–∞–µ–º
            del features, labels, outputs
            torch.cuda.empty_cache()
        
        return model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return None

def test_full_training_step(model, train_loader):
    """–¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è"""
    print("\nüîç –¢–ï–°–¢ –ü–û–õ–ù–û–ì–û –®–ê–ì–ê –û–ë–£–ß–ï–ù–ò–Ø:")
    print("=" * 50)
    
    if not torch.cuda.is_available() or model is None:
        print("‚ùå GPU –∏–ª–∏ –º–æ–¥–µ–ª—å –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        return
    
    device = torch.device('cuda')
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    criterion = nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)
    
    model.train()
    torch.cuda.empty_cache()
    
    for i, batch in enumerate(train_loader):
        if i >= 2:  # –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–µ—Ä–≤—ã–µ 2 –±–∞—Ç—á–∞
            break
            
        features = batch['features'].to(device, non_blocking=True)
        labels = batch['labels'].to(device, non_blocking=True)
        
        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è –ø–æ–ª–Ω–æ–≥–æ —à–∞–≥–∞
        torch.cuda.synchronize()
        start_time = time.time()
        
        # Forward pass
        outputs = model(features)
        loss = criterion(outputs, labels)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        torch.cuda.synchronize()
        step_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
        current_memory = torch.cuda.memory_allocated() / 1024**3
        cached_memory = torch.cuda.memory_reserved() / 1024**3
        
        print(f"   –®–∞–≥ {i+1}:")
        print(f"     –ü–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è: {step_time:.3f} —Å–µ–∫")
        print(f"     Loss: {loss.item():.4f}")
        print(f"     –ü–∞–º—è—Ç—å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∞: {current_memory:.2f} GB")
        print(f"     –ü–∞–º—è—Ç—å –∑–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–∞: {cached_memory:.2f} GB")
        
        # –û—á–∏—â–∞–µ–º
        del features, labels, outputs, loss
        torch.cuda.empty_cache()

def check_system_resources():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
    print("\nüîç –°–ò–°–¢–ï–ú–ù–´–ï –†–ï–°–£–†–°–´:")
    print("=" * 50)
    
    # CPU
    cpu_percent = psutil.cpu_percent(interval=1)
    cpu_count = psutil.cpu_count()
    print(f"üìä CPU: {cpu_count} —è–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {cpu_percent:.1f}%")
    
    # RAM
    memory = psutil.virtual_memory()
    print(f"üìä RAM: {memory.total / 1024**3:.1f} GB –≤—Å–µ–≥–æ, {memory.used / 1024**3:.1f} GB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ ({memory.percent:.1f}%)")
    
    # –î–∏—Å–∫
    disk = psutil.disk_usage('/')
    print(f"üìä –î–∏—Å–∫: {disk.total / 1024**3:.1f} GB –≤—Å–µ–≥–æ, {disk.used / 1024**3:.1f} GB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    data_path = Path("../data/google_asl_signs")
    if data_path.exists():
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã: {data_path}")
        # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä
        total_size = 0
        file_count = 0
        for root, dirs, files in os.walk(data_path):
            for file in files:
                file_path = os.path.join(root, file)
                total_size += os.path.getsize(file_path)
                file_count += 1
        print(f"üìä –§–∞–π–ª–æ–≤: {file_count:,}, –†–∞–∑–º–µ—Ä: {total_size / 1024**3:.1f} GB")
    else:
        print(f"‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {data_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞"""
    print("üîç –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò –û–ë–£–ß–ï–ù–ò–Ø")
    print("=" * 70)
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    gpu_ok = check_gpu_usage()
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
    check_system_resources()
    
    # 3. –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    train_loader, val_loader, test_loader = test_data_loading_speed()
    
    if train_loader is not None:
        # 4. –¢–µ—Å—Ç –ø–µ—Ä–µ–¥–∞—á–∏ –Ω–∞ GPU
        test_gpu_transfer_speed(train_loader)
        
        # 5. –¢–µ—Å—Ç forward pass
        model = test_model_forward_pass(train_loader)
        
        # 6. –¢–µ—Å—Ç –ø–æ–ª–Ω–æ–≥–æ —à–∞–≥–∞ –æ–±—É—á–µ–Ω–∏—è
        test_full_training_step(model, train_loader)
    
    print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 50)
    
    if not gpu_ok:
        print("‚ùå –ü—Ä–æ–±–ª–µ–º–∞: GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üí° –†–µ—à–µ–Ω–∏–µ: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA –∏ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA")
    else:
        print("‚úÖ GPU —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        if train_loader is None:
            print("‚ùå –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
            print("üí° –†–µ—à–µ–Ω–∏—è:")
            print("   - –£–º–µ–Ω—å—à–∏—Ç–µ num_workers –¥–æ 2")
            print("   - –û—Ç–∫–ª—é—á–∏—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ –≤—Ä–µ–º–µ–Ω–Ω–æ")
            print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å –¥–∏—Å–∫–∞")
        else:
            print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç")
            print("üí° –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è:")
            print("   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SSD –¥–ª—è –¥–∞–Ω–Ω—ã—Ö")
            print("   - –£–≤–µ–ª–∏—á—å—Ç–µ batch_size –µ—Å–ª–∏ –ø–æ–∑–≤–æ–ª—è–µ—Ç –ø–∞–º—è—Ç—å")
            print("   - –í–∫–ª—é—á–∏—Ç–µ mixed precision")

if __name__ == "__main__":
    main() 