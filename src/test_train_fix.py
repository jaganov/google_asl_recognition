#!/usr/bin/env python3
"""
–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ train.py —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ RTX 4070 (Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
"""

import torch
import sys
import os

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from train import ASLTrainer
from data_loader import ASLDataLoader
from preprocessing import ASLPreprocessor
from augmentations import ASLAugmentations

# –°–±—Ä–æ—Å —Ñ–ª–∞–≥–∞ –¥–ª—è —á–∏—Å—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞
if hasattr(ASLPreprocessor, '_landmarks_printed'):
    delattr(ASLPreprocessor, '_landmarks_printed')

def test_train_fix():
    """–¢–µ—Å—Ç –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–æ–≥–æ train.py —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ (Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)"""
    print("üß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π train.py —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ RTX 4070 (Windows)...")
    
    try:
        # 1. –¢–µ—Å—Ç –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–π
        print("\n1. –¢–µ—Å—Ç–∏—Ä—É–µ–º –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏...")
        augmenter = ASLAugmentations()
        test_features = torch.randn(2, 50, 468 * 3 * 3)  # (batch, frames, features)
        augmented = augmenter(test_features)
        print(f"   ‚úÖ –ê—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏ —Ä–∞–±–æ—Ç–∞—é—Ç: {test_features.shape} -> {augmented.shape}")
        
        # 2. –¢–µ—Å—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ (—É–±–∏—Ä–∞–µ–º –æ—Ç–¥–µ–ª—å–Ω—ã–π —Ç–µ—Å—Ç)
        print("\n2. –¢–µ—Å—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä–∞ –±—É–¥–µ—Ç –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ DataLoader...")
        
        # 3. –¢–µ—Å—Ç DataLoader —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏
        print("\n3. –¢–µ—Å—Ç–∏—Ä—É–µ–º DataLoader —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏...")
        dataloader = ASLDataLoader(
            data_dir="../data/google_asl_signs",
            batch_size=4,
            max_len=64,
            preprocessor=None  # DataLoader —Å–æ–∑–¥–∞—Å—Ç –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—Å–æ—Ä —Å–∞–º
        )
        
        # –ü–æ–ª—É—á–∞–µ–º DataLoader'—ã —Å –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏—è–º–∏
        train_loader, val_loader, test_loader = dataloader.get_dataloaders(
            augment_train=True
        )
        
        # –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–∏–Ω –±–∞—Ç—á
        sample_batch = next(iter(train_loader))
        print(f"   ‚úÖ DataLoader —Ä–∞–±–æ—Ç–∞–µ—Ç: {sample_batch['features'].shape}")
        print(f"   ‚úÖ –ö–ª—é—á–∏ –±–∞—Ç—á–∞: {list(sample_batch.keys())}")
        
        # 4. –¢–µ—Å—Ç —Ç—Ä–µ–Ω–µ—Ä–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ (Windows-—Å–æ–≤–º–µ—Å—Ç–∏–º—ã–π)
        print("\n4. –¢–µ—Å—Ç–∏—Ä—É–µ–º —Ç—Ä–µ–Ω–µ—Ä —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏ RTX 4070 (Windows)...")
        trainer = ASLTrainer(
            data_dir="../data/google_asl_signs",
            model_dir="models/test",
            max_len=64,
            batch_size=4,
            dim=64,  # –ú–∞–ª–µ–Ω—å–∫–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
            lr=1e-3,
            epochs=2,
            use_augmentations=True,
            use_mixed_precision=True,  # –¢–µ—Å—Ç–∏—Ä—É–µ–º mixed precision
            gradient_clip_val=1.0,     # –¢–µ—Å—Ç–∏—Ä—É–µ–º gradient clipping
            gradient_accumulation_steps=2  # –¢–µ—Å—Ç–∏—Ä—É–µ–º gradient accumulation
        )
        
        print(f"   ‚úÖ –¢—Ä–µ–Ω–µ—Ä —Å–æ–∑–¥–∞–Ω —É—Å–ø–µ—à–Ω–æ")
        print(f"   ‚úÖ –ú–æ–¥–µ–ª—å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤: {sum(p.numel() for p in trainer.model.parameters()):,}")
        print(f"   ‚úÖ Mixed precision: {'–í–∫–ª—é—á–µ–Ω' if trainer.use_mixed_precision else '–û—Ç–∫–ª—é—á–µ–Ω'}")
        print(f"   ‚úÖ Gradient clipping: {trainer.gradient_clip_val}")
        print(f"   ‚úÖ Gradient accumulation: {trainer.gradient_accumulation_steps} steps")
        
        # 5. –¢–µ—Å—Ç –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        print("\n5. –¢–µ—Å—Ç–∏—Ä—É–µ–º –æ–¥–Ω—É —ç–ø–æ—Ö—É –æ–±—É—á–µ–Ω–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏...")
        try:
            train_loss, train_acc = trainer.train_epoch(0)
            print(f"   ‚úÖ –û–±—É—á–µ–Ω–∏–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: Loss={train_loss:.4f}, Acc={train_acc:.2f}%")
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –æ–±—É—á–µ–Ω–∏–∏: {e}")
            print("   ‚ÑπÔ∏è –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å Windows-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏")
            return False
        
        # 6. –¢–µ—Å—Ç –≤–∞–ª–∏–¥–∞—Ü–∏–∏ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏
        print("\n6. –¢–µ—Å—Ç–∏—Ä—É–µ–º –≤–∞–ª–∏–¥–∞—Ü–∏—é —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏...")
        try:
            val_loss, val_acc = trainer.validate(0)
            print(f"   ‚úÖ –í–∞–ª–∏–¥–∞—Ü–∏—è —Ä–∞–±–æ—Ç–∞–µ—Ç: Loss={val_loss:.4f}, Acc={val_acc:.2f}%")
        except Exception as e:
            print(f"   ‚ö†Ô∏è –û—à–∏–±–∫–∞ –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏: {e}")
            print("   ‚ÑπÔ∏è –≠—Ç–æ –º–æ–∂–µ—Ç –±—ã—Ç—å —Å–≤—è–∑–∞–Ω–æ —Å Windows-—Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã–º–∏ –ø—Ä–æ–±–ª–µ–º–∞–º–∏")
            return False
        
        # 7. –¢–µ—Å—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ GPU
        if torch.cuda.is_available():
            print("\n7. –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ GPU:")
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"   ‚úÖ GPU: {gpu_name}")
            print(f"   ‚úÖ –ü–∞–º—è—Ç—å: {gpu_memory:.1f} GB")
            
            # –¢–µ—Å—Ç –ø–∞–º—è—Ç–∏ –≤–æ –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
            gpu_memory_used = torch.cuda.memory_allocated() / 1024**3
            gpu_memory_cached = torch.cuda.memory_reserved() / 1024**3
            print(f"   ‚úÖ –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ: {gpu_memory_used:.1f} GB")
            print(f"   ‚úÖ –ó–∞—Ä–µ–∑–µ—Ä–≤–∏—Ä–æ–≤–∞–Ω–æ: {gpu_memory_cached:.1f} GB")
        
        # 8. –¢–µ—Å—Ç PyTorch compile (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ)
        import platform
        if hasattr(torch, 'compile'):
            print("\n8. PyTorch 2.0+ compile:")
            print(f"   ‚úÖ PyTorch compile –¥–æ—Å—Ç—É–ø–µ–Ω")
            if platform.system() == 'Windows':
                print(f"   ‚ÑπÔ∏è PyTorch compile –æ—Ç–∫–ª—é—á–µ–Ω –¥–ª—è Windows (–∏–∑–±–µ–≥–∞–µ–º Triton)")
            else:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ compile –Ω–∞ Linux/Mac
                try:
                    test_model = torch.nn.Linear(10, 1)
                    compiled_model = torch.compile(test_model, mode='reduce-overhead')
                    test_input = torch.randn(1, 10)
                    _ = compiled_model(test_input)
                    print(f"   ‚úÖ PyTorch compile —Ä–∞–±–æ—Ç–∞–µ—Ç")
                except Exception as e:
                    print(f"   ‚ö†Ô∏è PyTorch compile –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç: {e}")
                    print(f"   ‚ÑπÔ∏è –≠—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ - –æ–±—É—á–µ–Ω–∏–µ –±—É–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –±–µ–∑ compile")
        else:
            print("\n8. PyTorch 2.0+ compile:")
            print(f"   ‚ö†Ô∏è PyTorch compile –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω (–Ω—É–∂–µ–Ω PyTorch 2.0+)")
        
        print("\nüéâ –í—Å–µ —Ç–µ—Å—Ç—ã –ø—Ä–æ—à–ª–∏ —É—Å–ø–µ—à–Ω–æ!")
        print("‚úÖ train.py –∏—Å–ø—Ä–∞–≤–ª–µ–Ω –∏ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω –¥–ª—è RTX 4070 (Windows)")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞ –≤ —Ç–µ—Å—Ç–µ: {e}")
        import traceback
        traceback.print_exc()
        return False

if __name__ == "__main__":
    success = test_train_fix()
    if success:
        print("\nüöÄ –ú–æ–∂–Ω–æ –∑–∞–ø—É—Å–∫–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è–º–∏!")
        print("python train.py")
    else:
        print("\n‚ö†Ô∏è –ù—É–∂–Ω–æ –∏—Å–ø—Ä–∞–≤–∏—Ç—å –æ—à–∏–±–∫–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º –æ–±—É—á–µ–Ω–∏—è") 