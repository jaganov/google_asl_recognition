# quick_performance_test.py
import torch
import time
import psutil
import os
from pathlib import Path

def quick_gpu_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç GPU"""
    print("üîç –ë–´–°–¢–†–´–ô –¢–ï–°–¢ GPU:")
    print("=" * 40)
    
    if not torch.cuda.is_available():
        print("‚ùå CUDA –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
        return False
    
    print(f"‚úÖ CUDA –¥–æ—Å—Ç—É–ø–µ–Ω")
    print(f"‚úÖ GPU: {torch.cuda.get_device_name(0)}")
    print(f"‚úÖ –ü–∞–º—è—Ç—å: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
    
    # –¢–µ—Å—Ç –ø–∞–º—è—Ç–∏
    torch.cuda.empty_cache()
    initial_memory = torch.cuda.memory_allocated() / 1024**3
    print(f"üìä –ù–∞—á–∞–ª—å–Ω–∞—è –ø–∞–º—è—Ç—å: {initial_memory:.2f} GB")
    
    # –°–æ–∑–¥–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–π —Ç–µ–Ω–∑–æ—Ä
    test_tensor = torch.randn(1000, 1000).cuda()
    memory_after = torch.cuda.memory_allocated() / 1024**3
    print(f"üìä –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ —Å–æ–∑–¥–∞–Ω–∏—è —Ç–µ–Ω–∑–æ—Ä–∞: {memory_after:.2f} GB")
    
    # –¢–µ—Å—Ç –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
    start_time = time.time()
    result = torch.mm(test_tensor, test_tensor)
    torch.cuda.synchronize()
    compute_time = time.time() - start_time
    print(f"‚è±Ô∏è –í—Ä–µ–º—è –º–∞—Ç—Ä–∏—á–Ω–æ–≥–æ —É–º–Ω–æ–∂–µ–Ω–∏—è: {compute_time:.3f} —Å–µ–∫")
    
    # –û—á–∏—â–∞–µ–º
    del test_tensor, result
    torch.cuda.empty_cache()
    
    return True

def quick_data_loading_test():
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö"""
    print("\nüîç –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ó–ê–ì–†–£–ó–ö–ò –î–ê–ù–ù–´–•:")
    print("=" * 40)
    
    try:
        from data_loader import ASLDataLoader
        
        print("üìÇ –°–æ–∑–¥–∞–µ–º DataLoader...")
        start_time = time.time()
        
        dataloader = ASLDataLoader(
            data_dir="../data/google_asl_signs",
            batch_size=8,  # –ú–∞–ª–µ–Ω—å–∫–∏–π batch –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ —Ç–µ—Å—Ç–∞
            max_len=128,   # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å
            num_workers=1  # –û–¥–∏–Ω –≤–æ—Ä–∫–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∞
        )
        
        load_time = time.time() - start_time
        print(f"‚úÖ DataLoader —Å–æ–∑–¥–∞–Ω –∑–∞ {load_time:.2f} —Å–µ–∫")
        
        # –ü–æ–ª—É—á–∞–µ–º dataloaders
        print("üìÇ –ü–æ–ª—É—á–∞–µ–º dataloaders...")
        start_time = time.time()
        train_loader, val_loader, test_loader = dataloader.get_dataloaders(augment_train=False)
        dataloader_time = time.time() - start_time
        print(f"‚úÖ DataLoader'—ã —Å–æ–∑–¥–∞–Ω—ã –∑–∞ {dataloader_time:.2f} —Å–µ–∫")
        
        print(f"üìä Train batches: {len(train_loader)}")
        print(f"üìä Val batches: {len(val_loader)}")
        print(f"üìä Test batches: {len(test_loader)}")
        
        # –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
        print("\nüìÇ –¢–µ—Å—Ç–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞...")
        start_time = time.time()
        
        for i, batch in enumerate(train_loader):
            if i >= 2:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –±–∞—Ç—á–∞
                break
            batch_time = time.time() - start_time
            print(f"   –ë–∞—Ç—á {i+1}: {batch_time:.2f} —Å–µ–∫")
            print(f"   –†–∞–∑–º–µ—Ä: {batch['features'].shape}")
            start_time = time.time()
        
        return train_loader
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

def quick_model_test(train_loader):
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –º–æ–¥–µ–ª–∏"""
    print("\nüîç –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –ú–û–î–ï–õ–ò:")
    print("=" * 40)
    
    if not torch.cuda.is_available() or train_loader is None:
        print("‚ùå GPU –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        return None
    
    try:
        from models import get_model
        
        device = torch.device('cuda')
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –∏–∑ –ø–µ—Ä–≤–æ–≥–æ –±–∞—Ç—á–∞
        sample_batch = next(iter(train_loader))
        input_dim = sample_batch['features'].shape[-1]
        
        print(f"üìä –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {input_dim}")
        
        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        print("ü§ñ –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å...")
        start_time = time.time()
        model = get_model(
            input_dim=input_dim,
            num_classes=250,
            max_len=128,  # –ö–æ—Ä–æ—Ç–∫–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –¥–ª—è —Ç–µ—Å—Ç–∞
            dim=128       # –ú–µ–Ω—å—à–∞—è –º–æ–¥–µ–ª—å –¥–ª—è —Ç–µ—Å—Ç–∞
        ).to(device)
        model_time = time.time() - start_time
        print(f"‚úÖ –ú–æ–¥–µ–ª—å —Å–æ–∑–¥–∞–Ω–∞ –∑–∞ {model_time:.2f} —Å–µ–∫")
        print(f"üìä –ü–∞—Ä–∞–º–µ—Ç—Ä—ã: {sum(p.numel() for p in model.parameters()):,}")
        
        # –¢–µ—Å—Ç forward pass
        model.train()
        torch.cuda.empty_cache()
        
        print("\nüìä –¢–µ—Å—Ç–∏—Ä—É–µ–º forward pass...")
        for i, batch in enumerate(train_loader):
            if i >= 2:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –±–∞—Ç—á–∞
                break
                
            features = batch['features'].to(device, non_blocking=True)
            labels = batch['labels'].to(device, non_blocking=True)
            
            # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
            torch.cuda.synchronize()
            start_time = time.time()
            
            with torch.no_grad():
                outputs = model(features)
            
            torch.cuda.synchronize()
            forward_time = time.time() - start_time
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
            memory_used = torch.cuda.memory_allocated() / 1024**3
            
            print(f"   –ë–∞—Ç—á {i+1}:")
            print(f"     Forward pass: {forward_time:.3f} —Å–µ–∫")
            print(f"     –ü–∞–º—è—Ç—å: {memory_used:.2f} GB")
            print(f"     –†–∞–∑–º–µ—Ä –≤—ã—Ö–æ–¥–æ–≤: {outputs.shape}")
            
            # –û—á–∏—â–∞–µ–º
            del features, labels, outputs
            torch.cuda.empty_cache()
        
        return model
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –º–æ–¥–µ–ª–∏: {e}")
        return None

def quick_training_test(model, train_loader):
    """–ë—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è"""
    print("\nüîç –ë–´–°–¢–†–´–ô –¢–ï–°–¢ –û–ë–£–ß–ï–ù–ò–Ø:")
    print("=" * 40)
    
    if not torch.cuda.is_available() or model is None or train_loader is None:
        print("‚ùå GPU, –º–æ–¥–µ–ª—å –∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã")
        return
    
    device = torch.device('cuda')
    
    # –ù–∞—Å—Ç—Ä–æ–π–∫–∏
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)
    
    model.train()
    torch.cuda.empty_cache()
    
    print("üìä –¢–µ—Å—Ç–∏—Ä—É–µ–º –ø–æ–ª–Ω—ã–π —à–∞–≥ –æ–±—É—á–µ–Ω–∏—è...")
    for i, batch in enumerate(train_loader):
        if i >= 2:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –±–∞—Ç—á–∞
            break
            
        features = batch['features'].to(device, non_blocking=True)
        labels = batch['labels'].to(device, non_blocking=True)
        
        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è
        torch.cuda.synchronize()
        start_time = time.time()
        
        # Forward pass
        outputs = model(features)
        loss = criterion(outputs, labels)
        
        # Backward pass
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()
        
        torch.cuda.synchronize()
        step_time = time.time() - start_time
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–∞–º—è—Ç—å
        memory_used = torch.cuda.memory_allocated() / 1024**3
        
        print(f"   –®–∞–≥ {i+1}:")
        print(f"     –ü–æ–ª–Ω–æ–µ –≤—Ä–µ–º—è: {step_time:.3f} —Å–µ–∫")
        print(f"     Loss: {loss.item():.4f}")
        print(f"     –ü–∞–º—è—Ç—å: {memory_used:.2f} GB")
        
        # –û—á–∏—â–∞–µ–º
        del features, labels, outputs, loss
        torch.cuda.empty_cache()

def check_system_resources():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤"""
    print("\nüîç –°–ò–°–¢–ï–ú–ù–´–ï –†–ï–°–£–†–°–´:")
    print("=" * 40)
    
    # CPU
    cpu_percent = psutil.cpu_percent(interval=1)
    cpu_count = psutil.cpu_count()
    print(f"üìä CPU: {cpu_count} —è–¥–µ—Ä, –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: {cpu_percent:.1f}%")
    
    # RAM
    memory = psutil.virtual_memory()
    print(f"üìä RAM: {memory.total / 1024**3:.1f} GB –≤—Å–µ–≥–æ, {memory.used / 1024**3:.1f} GB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ ({memory.percent:.1f}%)")
    
    # –î–∏—Å–∫
    try:
        disk = psutil.disk_usage('/')
        print(f"üìä –î–∏—Å–∫: {disk.total / 1024**3:.1f} GB –≤—Å–µ–≥–æ, {disk.used / 1024**3:.1f} GB –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–æ")
    except:
        print("üìä –î–∏—Å–∫: –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    data_path = Path("../data/google_asl_signs")
    if data_path.exists():
        print(f"‚úÖ –î–∞–Ω–Ω—ã–µ –Ω–∞–π–¥–µ–Ω—ã: {data_path}")
        # –ë—ã—Å—Ç—Ä–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑–º–µ—Ä–∞
        try:
            total_size = 0
            file_count = 0
            for root, dirs, files in os.walk(data_path):
                for file in files[:100]:  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 100 —Ñ–∞–π–ª–æ–≤ –¥–ª—è —Å–∫–æ—Ä–æ—Å—Ç–∏
                    file_path = os.path.join(root, file)
                    total_size += os.path.getsize(file_path)
                    file_count += 1
                break  # –¢–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–π —É—Ä–æ–≤–µ–Ω—å
            print(f"üìä –ü—Ä–∏–º–µ—Ä–Ω—ã–π —Ä–∞–∑–º–µ—Ä (–ø–µ—Ä–≤—ã–µ 100 —Ñ–∞–π–ª–æ–≤): {total_size / 1024**3:.1f} GB")
        except:
            print("üìä –†–∞–∑–º–µ—Ä –¥–∞–Ω–Ω—ã—Ö: –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å")
    else:
        print(f"‚ùå –î–∞–Ω–Ω—ã–µ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã: {data_path}")

def main():
    """–û—Å–Ω–æ–≤–Ω–æ–π –±—ã—Å—Ç—Ä—ã–π —Ç–µ—Å—Ç"""
    print("üîç –ë–´–°–¢–†–ê–Ø –î–ò–ê–ì–ù–û–°–¢–ò–ö–ê –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–ò")
    print("=" * 60)
    
    # 1. –ü—Ä–æ–≤–µ—Ä–∫–∞ GPU
    gpu_ok = quick_gpu_test()
    
    # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–∏—Å—Ç–µ–º–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
    check_system_resources()
    
    # 3. –¢–µ—Å—Ç –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö
    train_loader = quick_data_loading_test()
    
    if train_loader is not None:
        # 4. –¢–µ—Å—Ç –º–æ–¥–µ–ª–∏
        model = quick_model_test(train_loader)
        
        # 5. –¢–µ—Å—Ç –æ–±—É—á–µ–Ω–∏—è
        quick_training_test(model, train_loader)
    
    print("\nüéØ –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:")
    print("=" * 40)
    
    if not gpu_ok:
        print("‚ùå –ü—Ä–æ–±–ª–µ–º–∞: GPU –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
        print("üí° –†–µ—à–µ–Ω–∏–µ: –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ CUDA –∏ PyTorch —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π CUDA")
    else:
        print("‚úÖ GPU —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ")
        
        if train_loader is None:
            print("‚ùå –ü—Ä–æ–±–ª–µ–º–∞: –ú–µ–¥–ª–µ–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
            print("üí° –†–µ—à–µ–Ω–∏—è:")
            print("   - –£–º–µ–Ω—å—à–∏—Ç–µ num_workers –¥–æ 1")
            print("   - –û—Ç–∫–ª—é—á–∏—Ç–µ –∞—É–≥–º–µ–Ω—Ç–∞—Ü–∏–∏")
            print("   - –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–∫–æ—Ä–æ—Å—Ç—å –¥–∏—Å–∫–∞")
        else:
            print("‚úÖ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Ä–∞–±–æ—Ç–∞–µ—Ç")
            print("üí° –î–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è:")
            print("   - –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ SSD –¥–ª—è –¥–∞–Ω–Ω—ã—Ö")
            print("   - –£–≤–µ–ª–∏—á—å—Ç–µ batch_size")
            print("   - –í–∫–ª—é—á–∏—Ç–µ mixed precision")

if __name__ == "__main__":
    main() 